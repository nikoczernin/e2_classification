{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cd27d5-c355-48b5-a57d-046522c1f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978cfdb7-3081-4be9-aa6c-eb9f4c8759c4",
   "metadata": {},
   "source": [
    "# Load pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f41f79-066b-4b98-9cda-3aa4aa60d349",
   "metadata": {},
   "source": [
    "## Dataset 1: Biomed data on muscular dystropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e55138-fe0a-4e4a-8331-a1f4d657da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/biomed/preprocessed_biomed_data.pickle', 'rb') as handle:\n",
    "    x_biomed_train, y_biomed_train, x_biomed_test, y_biomed_test = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f3baf-8050-4e7f-aec2-c26f65c64a2b",
   "metadata": {},
   "source": [
    "## Dataset 2: Fertility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5d2adb-1450-47b5-b958-df96a8b74919",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/fertility/fertility_preprocessed.pickle', 'rb') as handle:\n",
    "    x_fert_train, y_fert_train, x_fert_test, y_fert_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812c539-c8ef-46ca-bab6-3e1d9ca3a2b5",
   "metadata": {},
   "source": [
    "## Dataset 3: Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e877c7-ddfd-4905-a728-ab9d616d95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reviews/preprocessed_reviews_data.pickle', 'rb') as handle:\n",
    "    x_reviews_train, y_reviews_train, x_reviews_test, y_reviews_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b640f-d78b-45ca-b0b8-e6d7e89d50f7",
   "metadata": {},
   "source": [
    "## Dataset 4: Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4037ee-4028-4543-aab8-edd9416a5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/congress/preprocessed_congress_data.pickle', 'rb') as handle:\n",
    "    x_congress_train, y_congress_train, x_congress_test, y_congress_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1ee12-b00d-4c4f-b269-e90db239e6de",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "The following datasets ahve the following variables to use for the prediction:\n",
    "\n",
    "- Biomed: `x_biomed_train`, `y_biomed_train`, `x_biomed_test`, `y_biomed_test`\n",
    "- Fertility: `x_fert_train`, `y_fert_train`, `x_fert_test`, `y_fert_test`\n",
    "- Reviews: `x_reviews_train`, `y_reviews_train`, `x_reviews_test`\n",
    "- Congress: `x_congress_train`, `y_congress_train`, `x_congress_test`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0dbf5d-59a6-48e7-a531-2f310850d6e7",
   "metadata": {},
   "source": [
    "## Classifier 3: Multilayer Perceptron\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1878204f-d6b6-47a5-840d-692efa252be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "1 - 1\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 0\n",
      "1 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 1\n",
      "1 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "1 - 0\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "1 - 1\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "0 - 0\n",
      "1 - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parameters, as lists, so that I can change them more easily\n",
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "\n",
    "# assigning my faetures and classes to generic names for easier switching\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "\n",
    "# more parameters\n",
    "hidden_layers = (8,6,1)\n",
    "\n",
    "# creating the model\n",
    "mlp = MLPClassifier(hidden_layer_sizes = hidden_layers, \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = activation_functions[1], \n",
    "                    solver=solvers[-1], \n",
    "                    random_state=123 # kind of seed\n",
    "                   )\n",
    "# creating a pipeline\n",
    "pipe = Pipeline(steps=[('mlpc', mlp)])\n",
    "# training\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "# printing the score (its the accuracy, that can be changed somewhere)\n",
    "print(pipe.score(x_biomed_test, y_biomed_test))\n",
    "\n",
    "# making predictions\n",
    "y_biomed_test_pred = pipe.predict(x_biomed_test)\n",
    "# printing out the results of my prediction vs the actual class values\n",
    "for i,x in enumerate(y_biomed_test):\n",
    "    print(x, \"-\", y_biomed_test_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f272f313-c92b-457a-9abd-caa2624b37b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.91666667 0.66666667 0.75       0.83333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9082782  0.94117647 0.84271284 0.90562771 0.87878788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "learning_rate_init = 0.001 # default 0.001\n",
    "\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "\n",
    "\n",
    "hidden_layers = (8,6,1)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = hidden_layers, \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = activation_functions[1], \n",
    "                    solver=solvers[-1], \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "\n",
    "# cross validating\n",
    "# first param is the model incl its params, second is features, \n",
    "# third is class labels, cv is the k of k-fold-CV, scoring is the wanted scores\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=5, scoring=\"recall\"))\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=5, scoring=\"f1_weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae4aaf-d386-48c5-9eef-d41bc4dbd1fb",
   "metadata": {},
   "source": [
    "### how many hidden neurons should we use?\n",
    "\n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "#### Suggestion (rule of thumb):\n",
    "\n",
    "$\\frac{N_s}{(\\alpha*(N_i+N_o))}$\n",
    "\n",
    "$N_i$ = number of input neurons\n",
    "\n",
    "$N_o$ = number of output neurons\n",
    "\n",
    "$N_s$ = number of samples in training data\n",
    "\n",
    "$\\alpha$ = scaling factor $\\in [2,10]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a0342-bcb0-4ac7-b024-916426dcb7bb",
   "metadata": {},
   "source": [
    "### MLP: biomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83c5530e-bbbf-4d68-816c-439cf80b29c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622727272727273\n",
      "0.8774547773758974\n",
      "0.8805147058823529\n",
      "\n",
      "0.8577272727272728\n",
      "0.8718309893991683\n",
      "0.8746323529411765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8756060606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8899547773758973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8930147058823529\n",
      "\n",
      "0.8622727272727273\n",
      "0.8774547773758974\n",
      "0.8805147058823529\n",
      "\n",
      "0.8506060606060606\n",
      "0.8680187428222157\n",
      "0.8746323529411765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8639393939393939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831721620238244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/nikolaus/Documents/Uni/TU/Machine Learning/1_dataset_description/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871323529411764\n",
      "\n",
      "0.8925757575757576\n",
      "0.9078433107103183\n",
      "0.9102941176470589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wie viele layers und wie groß?\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (2), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (4), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (4, 2), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (4, 3), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 2), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"logistic\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 4), \n",
    "                                        max_iter=500, # epochs\n",
    "                                        activation = \"relu\", \n",
    "                                        solver=\"lbfgs\", \n",
    "                                        #learning_rate = learning_rate,\n",
    "                                        #learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"balanced_accuracy\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall_weighted\").mean())\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e97c6-f91f-481d-9cf3-3559af3f837f",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cdd8a76-5898-4e7e-a2fd-9a345d10df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# performing cross-fold validation on the training data to evaluate best parameters\n",
    "\n",
    "biomed_results = pd.DataFrame(columns=[\"classifier\", \"balanced_accuracy\", \n",
    "                                       \"f1_weighted\", \"recall\", \n",
    "                                       \"precision\", \"time_taken\", \"activation_function\", \n",
    "                                       \"solver\", \"learning_rate\", \"hidden_layer\"])\n",
    "\n",
    "# the scores we want\n",
    "scoring = {'balanced_accuracy': 'balanced_accuracy',\n",
    "           'f1_weighted': 'f1_weighted',\n",
    "           'precision_weighted': 'precision_weighted',\n",
    "           'recall_weighted': 'recall_weighted'}\n",
    "\n",
    "# filter out warnings (not sure if this is a good idea)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "\n",
    "#hidden_layers = (8,6,1)\n",
    "#hidden_layers = (100)\n",
    "hidden_layers = [\n",
    "    (2),\n",
    "    (4),\n",
    "    (6),\n",
    "    (4, 2),\n",
    "    (4, 4),\n",
    "    (6, 2),\n",
    "    (6, 4),\n",
    "    (6, 4, 2),\n",
    "]\n",
    "\n",
    "# running index\n",
    "i = 0\n",
    "\n",
    "# cross-validation k\n",
    "k = 10\n",
    "\n",
    "\n",
    "# only do the computation, if the following flag is true\n",
    "# it takes an hour or so to compute this, not necessary\n",
    "if True:\n",
    "    # iterate through all parameter permutations\n",
    "    # save accuracy, f1, precisiona and recall\n",
    "    for activation_function in activation_functions:\n",
    "        for solver in solvers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for hidden_layer in hidden_layers:\n",
    "                    \n",
    "                    # make a model\n",
    "                    mlp = MLPClassifier(hidden_layer_sizes = hidden_layer, \n",
    "                                        max_iter=300, # epochs\n",
    "                                        activation = activation_function, \n",
    "                                        solver=solver, \n",
    "                                        learning_rate = learning_rate,\n",
    "                                        learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "\n",
    "                    # cross_validate() returns a dictionary with results\n",
    "                    # cv = k for f-fold cross-validation\n",
    "                    cv_results = cross_validate(mlp, x_train, y_train, cv=k, scoring=scoring, return_train_score=True)\n",
    "                    \n",
    "                    # extract the result values and take the mean of the k iterations\n",
    "                    fit_time = cv_results[\"fit_time\"].mean()\n",
    "                    balanced_accuracy = cv_results[\"test_balanced_accuracy\"].mean()\n",
    "                    f1_weighted = cv_results[\"test_f1_weighted\"].mean()\n",
    "                    recall = cv_results[\"test_recall_weighted\"].mean()\n",
    "                    precision = cv_results[\"test_precision_weighted\"].mean()\n",
    "              \n",
    "                    # print out the running number, the accuracy and the parameters\n",
    "                    print(i, \"- acc:\", balanced_accuracy, \"-, time:\",  fit_time, end=\"\\r\")\n",
    "\n",
    "\n",
    "                    # save everything\n",
    "                    biomed_results = pd.concat([biomed_results, pd.DataFrame({\n",
    "                        \"classifier\": \"mlp\",\n",
    "                        \"balanced_accuracy\": balanced_accuracy,\n",
    "                        \"f1_weighted\": [f1_weighted],\n",
    "                        \"recall\": [recall],\n",
    "                        \"precision\": [precision],\n",
    "                        \"time_taken\": fit_time,\n",
    "                        \"activation_function\": activation_function,\n",
    "                        \"solver\": solver,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"hidden_layer\": str(hidden_layer)                        \n",
    "                    })], ignore_index=True)\n",
    "                    i += 1;\n",
    "    \n",
    "    # saving the results as a pickle\n",
    "    with open('data/biomed/biomed_results.pickle', 'wb') as handle:\n",
    "        pickle.dump(biomed_results, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddc34497-b861-4fe8-bdc4-b91ac548a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomed_results.to_csv(\"data/biomed/biomed_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac7c852f-7980-4d22-a992-99ee4a0f1fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.892576</td>\n",
       "      <td>0.907843</td>\n",
       "      <td>0.910294</td>\n",
       "      <td>0.919991</td>\n",
       "      <td>0.085247</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.892576</td>\n",
       "      <td>0.907843</td>\n",
       "      <td>0.910294</td>\n",
       "      <td>0.919991</td>\n",
       "      <td>0.082983</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.892576</td>\n",
       "      <td>0.907843</td>\n",
       "      <td>0.910294</td>\n",
       "      <td>0.919991</td>\n",
       "      <td>0.084893</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(6, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.151449</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.148197</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.117270</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.121541</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.896403</td>\n",
       "      <td>0.899632</td>\n",
       "      <td>0.917579</td>\n",
       "      <td>0.133092</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier  balanced_accuracy  f1_weighted    recall  precision  \\\n",
       "158        mlp           0.892576     0.907843  0.910294   0.919991   \n",
       "166        mlp           0.892576     0.907843  0.910294   0.919991   \n",
       "150        mlp           0.892576     0.907843  0.910294   0.919991   \n",
       "23         mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "7          mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "15         mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "5          mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "21         mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "13         mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "86         mlp           0.884848     0.896403  0.899632   0.917579   \n",
       "\n",
       "     time_taken activation_function solver learning_rate hidden_layer  \n",
       "158    0.085247                relu  lbfgs    invscaling       (6, 4)  \n",
       "166    0.082983                relu  lbfgs      adaptive       (6, 4)  \n",
       "150    0.084893                relu  lbfgs      constant       (6, 4)  \n",
       "23     0.151449            logistic  lbfgs      adaptive    (6, 4, 2)  \n",
       "7      0.148197            logistic  lbfgs      constant    (6, 4, 2)  \n",
       "15     0.153861            logistic  lbfgs    invscaling    (6, 4, 2)  \n",
       "5      0.117270            logistic  lbfgs      constant       (6, 2)  \n",
       "21     0.125265            logistic  lbfgs      adaptive       (6, 2)  \n",
       "13     0.121541            logistic  lbfgs    invscaling       (6, 2)  \n",
       "86     0.133092                tanh  lbfgs    invscaling       (6, 4)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.151449</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>0.148197</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(6, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.924786</td>\n",
       "      <td>0.057864</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.924786</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.117270</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.924786</td>\n",
       "      <td>0.059005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>0.917648</td>\n",
       "      <td>0.121541</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(6, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.892576</td>\n",
       "      <td>0.907843</td>\n",
       "      <td>0.910294</td>\n",
       "      <td>0.919991</td>\n",
       "      <td>0.082983</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(6, 4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier  balanced_accuracy  f1_weighted    recall  precision  \\\n",
       "23         mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "15         mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "7          mlp           0.890455     0.912551  0.916544   0.926143   \n",
       "72         mlp           0.878788     0.905071  0.911029   0.924786   \n",
       "80         mlp           0.878788     0.905071  0.911029   0.924786   \n",
       "5          mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "88         mlp           0.878788     0.905071  0.911029   0.924786   \n",
       "21         mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "13         mlp           0.886364     0.906814  0.911029   0.917648   \n",
       "166        mlp           0.892576     0.907843  0.910294   0.919991   \n",
       "\n",
       "     time_taken activation_function solver learning_rate hidden_layer  \n",
       "23     0.151449            logistic  lbfgs      adaptive    (6, 4, 2)  \n",
       "15     0.153861            logistic  lbfgs    invscaling    (6, 4, 2)  \n",
       "7      0.148197            logistic  lbfgs      constant    (6, 4, 2)  \n",
       "72     0.057864                tanh  lbfgs      constant            2  \n",
       "80     0.062135                tanh  lbfgs    invscaling            2  \n",
       "5      0.117270            logistic  lbfgs      constant       (6, 2)  \n",
       "88     0.059005                tanh  lbfgs      adaptive            2  \n",
       "21     0.125265            logistic  lbfgs      adaptive       (6, 2)  \n",
       "13     0.121541            logistic  lbfgs    invscaling       (6, 2)  \n",
       "166    0.082983                relu  lbfgs      adaptive       (6, 4)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the saved results\n",
    "with open('data/biomed/biomed_results.pickle', 'rb') as handle:\n",
    "    biomed_results = pickle.load(handle)\n",
    "\n",
    "display(biomed_results.sort_values(\"balanced_accuracy\", ascending=False).head(10))\n",
    "display(biomed_results.sort_values(\"recall\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1eb1d682-e3f3-400f-9499-ac1cce2aa7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.19026389211811207\n",
      "recall 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   1\n",
       "actual       \n",
       "1          15\n",
       "0          27"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bad example\n",
    "# this is the model with the highest recall\n",
    "# obviously it go there by just saying everyone has muscular dystrophy lol\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "# make a model\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (4), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"sgd\", \n",
    "                    learning_rate = \"invscaling\",\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "\n",
    "print(\"f1:\", cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(\"recall\", cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall\").mean())\n",
    "\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "pd.crosstab(y_biomed_test, mlp.predict(x_biomed_test), colnames=[\"predicted\"], rownames=[\"actual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af8a2efa-d8db-4d68-ac70-827e56518435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           77     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.81197D-01    |proj g|=  1.17790D-01\n",
      "\n",
      "At iterate    1    f=  6.52992D-01    |proj g|=  5.17792D-04\n",
      "\n",
      "At iterate    2    f=  6.52991D-01    |proj g|=  3.08558D-04\n",
      "\n",
      "At iterate    3    f=  6.52981D-01    |proj g|=  9.28675D-04\n",
      "\n",
      "At iterate    4    f=  6.52962D-01    |proj g|=  2.30968D-03\n",
      "\n",
      "At iterate    5    f=  6.52905D-01    |proj g|=  4.84661D-03\n",
      "\n",
      "At iterate    6    f=  6.52726D-01    |proj g|=  9.13231D-03\n",
      "\n",
      "At iterate    7    f=  6.49557D-01    |proj g|=  8.05513D-03\n",
      "\n",
      "At iterate    8    f=  6.49516D-01    |proj g|=  2.27553D-02\n",
      "\n",
      "At iterate    9    f=  6.38260D-01    |proj g|=  2.34352D-02\n",
      "\n",
      "At iterate   10    f=  6.30874D-01    |proj g|=  6.08264D-02\n",
      "\n",
      "At iterate   11    f=  5.20699D-01    |proj g|=  1.23179D-01\n",
      "\n",
      "At iterate   12    f=  5.20131D-01    |proj g|=  1.30946D-01\n",
      "\n",
      "At iterate   13    f=  4.16527D-01    |proj g|=  6.97130D-02\n",
      "\n",
      "At iterate   14    f=  3.95747D-01    |proj g|=  9.80505D-02\n",
      "\n",
      "At iterate   15    f=  3.36127D-01    |proj g|=  6.34158D-02\n",
      "\n",
      "At iterate   16    f=  3.26396D-01    |proj g|=  1.25656D-01\n",
      "\n",
      "At iterate   17    f=  3.09890D-01    |proj g|=  2.66922D-02\n",
      "\n",
      "At iterate   18    f=  3.03160D-01    |proj g|=  4.19153D-02\n",
      "\n",
      "At iterate   19    f=  3.01700D-01    |proj g|=  1.06292D-02\n",
      "\n",
      "At iterate   20    f=  3.00814D-01    |proj g|=  2.99930D-02\n",
      "\n",
      "At iterate   21    f=  2.96447D-01    |proj g|=  3.72477D-02\n",
      "\n",
      "At iterate   22    f=  2.85804D-01    |proj g|=  1.08113D-01\n",
      "\n",
      "At iterate   23    f=  2.70647D-01    |proj g|=  5.99540D-02\n",
      "\n",
      "At iterate   24    f=  2.61880D-01    |proj g|=  2.86435D-02\n",
      "\n",
      "At iterate   25    f=  2.59789D-01    |proj g|=  4.20505D-02\n",
      "\n",
      "At iterate   26    f=  2.58411D-01    |proj g|=  4.92118D-02\n",
      "\n",
      "At iterate   27    f=  2.55956D-01    |proj g|=  4.25069D-02\n",
      "\n",
      "At iterate   28    f=  2.49475D-01    |proj g|=  1.91210D-01\n",
      "\n",
      "At iterate   29    f=  2.44050D-01    |proj g|=  1.95386D-02\n",
      "\n",
      "At iterate   30    f=  2.43291D-01    |proj g|=  5.95892D-03\n",
      "\n",
      "At iterate   31    f=  2.42962D-01    |proj g|=  8.25879D-03\n",
      "\n",
      "At iterate   32    f=  2.42072D-01    |proj g|=  1.67015D-02\n",
      "\n",
      "At iterate   33    f=  2.40500D-01    |proj g|=  3.06708D-02\n",
      "\n",
      "At iterate   34    f=  2.39567D-01    |proj g|=  1.97956D-02\n",
      "\n",
      "At iterate   35    f=  2.38127D-01    |proj g|=  1.61628D-02\n",
      "\n",
      "At iterate   36    f=  2.36581D-01    |proj g|=  1.97463D-02\n",
      "\n",
      "At iterate   37    f=  2.35790D-01    |proj g|=  4.32397D-02\n",
      "\n",
      "At iterate   38    f=  2.33345D-01    |proj g|=  5.47717D-02\n",
      "\n",
      "At iterate   39    f=  2.32864D-01    |proj g|=  3.61120D-02\n",
      "\n",
      "At iterate   40    f=  2.31871D-01    |proj g|=  2.39283D-02\n",
      "\n",
      "At iterate   41    f=  2.30958D-01    |proj g|=  3.14556D-02\n",
      "\n",
      "At iterate   42    f=  2.30710D-01    |proj g|=  1.95374D-02\n",
      "\n",
      "At iterate   43    f=  2.30487D-01    |proj g|=  1.22195D-02\n",
      "\n",
      "At iterate   44    f=  2.30134D-01    |proj g|=  8.68188D-03\n",
      "\n",
      "At iterate   45    f=  2.29872D-01    |proj g|=  1.98501D-02\n",
      "\n",
      "At iterate   46    f=  2.29297D-01    |proj g|=  4.33356D-02\n",
      "\n",
      "At iterate   47    f=  2.28282D-01    |proj g|=  5.38058D-02\n",
      "\n",
      "At iterate   48    f=  2.27492D-01    |proj g|=  2.19857D-01\n",
      "\n",
      "At iterate   49    f=  2.24879D-01    |proj g|=  1.30264D-01\n",
      "\n",
      "At iterate   50    f=  2.21159D-01    |proj g|=  7.69094D-02\n",
      "\n",
      "At iterate   51    f=  2.20380D-01    |proj g|=  1.61293D-02\n",
      "\n",
      "At iterate   52    f=  2.20256D-01    |proj g|=  2.33802D-02\n",
      "\n",
      "At iterate   53    f=  2.19613D-01    |proj g|=  4.10752D-02\n",
      "\n",
      "At iterate   54    f=  2.17092D-01    |proj g|=  4.14796D-02\n",
      "\n",
      "At iterate   55    f=  2.16251D-01    |proj g|=  2.33018D-02\n",
      "\n",
      "At iterate   56    f=  2.13939D-01    |proj g|=  5.51663D-02\n",
      "\n",
      "At iterate   57    f=  2.11106D-01    |proj g|=  6.38718D-02\n",
      "\n",
      "At iterate   58    f=  2.07889D-01    |proj g|=  1.77493D-01\n",
      "\n",
      "At iterate   59    f=  2.04266D-01    |proj g|=  1.57256D-01\n",
      "\n",
      "At iterate   60    f=  2.02904D-01    |proj g|=  2.17168D-02\n",
      "\n",
      "At iterate   61    f=  2.01869D-01    |proj g|=  1.81183D-02\n",
      "\n",
      "At iterate   62    f=  2.00869D-01    |proj g|=  2.52830D-02\n",
      "\n",
      "At iterate   63    f=  1.99988D-01    |proj g|=  4.12791D-02\n",
      "\n",
      "At iterate   64    f=  1.99013D-01    |proj g|=  4.36342D-02\n",
      "\n",
      "At iterate   65    f=  1.98168D-01    |proj g|=  3.35187D-02\n",
      "\n",
      "At iterate   66    f=  1.96817D-01    |proj g|=  2.10335D-02\n",
      "\n",
      "At iterate   67    f=  1.95446D-01    |proj g|=  3.39913D-02\n",
      "\n",
      "At iterate   68    f=  1.89463D-01    |proj g|=  6.75179D-02\n",
      "\n",
      "At iterate   69    f=  1.89317D-01    |proj g|=  7.82806D-02\n",
      "\n",
      "At iterate   70    f=  1.86827D-01    |proj g|=  6.89891D-02\n",
      "\n",
      "At iterate   71    f=  1.86692D-01    |proj g|=  2.04346D-02\n",
      "\n",
      "At iterate   72    f=  1.86364D-01    |proj g|=  9.09464D-02\n",
      "\n",
      "At iterate   73    f=  1.85842D-01    |proj g|=  1.58949D-02\n",
      "\n",
      "At iterate   74    f=  1.85742D-01    |proj g|=  9.71940D-03\n",
      "\n",
      "At iterate   75    f=  1.85659D-01    |proj g|=  9.90307D-03\n",
      "\n",
      "At iterate   76    f=  1.85311D-01    |proj g|=  1.66202D-02\n",
      "\n",
      "At iterate   77    f=  1.84786D-01    |proj g|=  2.11783D-02\n",
      "\n",
      "At iterate   78    f=  1.83818D-01    |proj g|=  5.23237D-02\n",
      "\n",
      "At iterate   79    f=  1.83196D-01    |proj g|=  1.76093D-02\n",
      "\n",
      "At iterate   80    f=  1.83030D-01    |proj g|=  8.11866D-03\n",
      "\n",
      "At iterate   81    f=  1.82922D-01    |proj g|=  8.61451D-03\n",
      "\n",
      "At iterate   82    f=  1.82877D-01    |proj g|=  1.64210D-02\n",
      "\n",
      "At iterate   83    f=  1.82840D-01    |proj g|=  1.20555D-02\n",
      "\n",
      "At iterate   84    f=  1.82806D-01    |proj g|=  6.40097D-03\n",
      "\n",
      "At iterate   85    f=  1.82766D-01    |proj g|=  1.16741D-02\n",
      "\n",
      "At iterate   86    f=  1.82717D-01    |proj g|=  1.35870D-02\n",
      "\n",
      "At iterate   87    f=  1.82639D-01    |proj g|=  3.93222D-02\n",
      "\n",
      "At iterate   88    f=  1.82528D-01    |proj g|=  2.33423D-02\n",
      "\n",
      "At iterate   89    f=  1.82446D-01    |proj g|=  2.82731D-03\n",
      "\n",
      "At iterate   90    f=  1.82423D-01    |proj g|=  2.10205D-03\n",
      "\n",
      "At iterate   91    f=  1.82406D-01    |proj g|=  1.66657D-03\n",
      "\n",
      "At iterate   92    f=  1.82389D-01    |proj g|=  8.58808D-03\n",
      "\n",
      "At iterate   93    f=  1.82355D-01    |proj g|=  1.78650D-03\n",
      "\n",
      "At iterate   94    f=  1.82336D"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-01    |proj g|=  2.84189D-03\n",
      "\n",
      "At iterate   95    f=  1.82271D-01    |proj g|=  2.11433D-03\n",
      "\n",
      "At iterate   96    f=  1.82211D-01    |proj g|=  5.37546D-03\n",
      "\n",
      "At iterate   97    f=  1.82129D-01    |proj g|=  5.84879D-03\n",
      "\n",
      "At iterate   98    f=  1.82103D-01    |proj g|=  1.12551D-02\n",
      "\n",
      "At iterate   99    f=  1.81963D-01    |proj g|=  1.95619D-02\n",
      "\n",
      "At iterate  100    f=  1.81941D-01    |proj g|=  4.25585D-03\n",
      "\n",
      "At iterate  101    f=  1.81892D-01    |proj g|=  3.58800D-03\n",
      "\n",
      "At iterate  102    f=  1.81832D-01    |proj g|=  3.57263D-03\n",
      "\n",
      "At iterate  103    f=  1.81775D-01    |proj g|=  1.23247D-02\n",
      "\n",
      "At iterate  104    f=  1.81651D-01    |proj g|=  4.34341D-03\n",
      "\n",
      "At iterate  105    f=  1.81551D-01    |proj g|=  1.67673D-02\n",
      "\n",
      "At iterate  106    f=  1.81506D-01    |proj g|=  6.12692D-03\n",
      "\n",
      "At iterate  107    f=  1.81456D-01    |proj g|=  3.08793D-03\n",
      "\n",
      "At iterate  108    f=  1.81432D-01    |proj g|=  3.09173D-03\n",
      "\n",
      "At iterate  109    f=  1.81402D-01    |proj g|=  5.75400D-03\n",
      "\n",
      "At iterate  110    f=  1.81363D-01    |proj g|=  3.80633D-03\n",
      "\n",
      "At iterate  111    f=  1.81318D-01    |proj g|=  3.90019D-03\n",
      "\n",
      "At iterate  112    f=  1.81301D-01    |proj g|=  2.69539D-03\n",
      "\n",
      "At iterate  113    f=  1.81287D-01    |proj g|=  6.57128D-03\n",
      "\n",
      "At iterate  114    f=  1.81270D-01    |proj g|=  4.45837D-03\n",
      "\n",
      "At iterate  115    f=  1.81250D-01    |proj g|=  2.56438D-03\n",
      "\n",
      "At iterate  116    f=  1.81245D-01    |proj g|=  2.11129D-03\n",
      "\n",
      "At iterate  117    f=  1.81229D-01    |proj g|=  6.96990D-03\n",
      "\n",
      "At iterate  118    f=  1.81208D-01    |proj g|=  3.83345D-03\n",
      "\n",
      "At iterate  119    f=  1.81161D-01    |proj g|=  4.27569D-03\n",
      "\n",
      "At iterate  120    f=  1.81121D-01    |proj g|=  8.35970D-03\n",
      "\n",
      "At iterate  121    f=  1.81049D-01    |proj g|=  1.16031D-02\n",
      "\n",
      "At iterate  122    f=  1.80933D-01    |proj g|=  1.27314D-02\n",
      "\n",
      "At iterate  123    f=  1.80877D-01    |proj g|=  1.47510D-02\n",
      "\n",
      "At iterate  124    f=  1.80855D-01    |proj g|=  4.24897D-03\n",
      "\n",
      "At iterate  125    f=  1.80820D-01    |proj g|=  3.72125D-03\n",
      "\n",
      "At iterate  126    f=  1.80799D-01    |proj g|=  4.97192D-03\n",
      "\n",
      "At iterate  127    f=  1.80783D-01    |proj g|=  2.91219D-03\n",
      "\n",
      "At iterate  128    f=  1.80762D-01    |proj g|=  6.12467D-03\n",
      "\n",
      "At iterate  129    f=  1.80752D-01    |proj g|=  5.58339D-03\n",
      "\n",
      "At iterate  130    f=  1.80728D-01    |proj g|=  3.57390D-03\n",
      "\n",
      "At iterate  131    f=  1.80674D-01    |proj g|=  3.86206D-03\n",
      "\n",
      "At iterate  132    f=  1.80623D-01    |proj g|=  3.41363D-03\n",
      "\n",
      "At iterate  133    f=  1.80531D-01    |proj g|=  1.48890D-03\n",
      "\n",
      "At iterate  134    f=  1.80472D-01    |proj g|=  6.87275D-03\n",
      "\n",
      "At iterate  135    f=  1.80397D-01    |proj g|=  6.44626D-03\n",
      "\n",
      "At iterate  136    f=  1.80311D-01    |proj g|=  2.19213D-02\n",
      "\n",
      "At iterate  137    f=  1.80205D-01    |proj g|=  8.02558D-03\n",
      "\n",
      "At iterate  138    f=  1.80183D-01    |proj g|=  6.09512D-03\n",
      "\n",
      "At iterate  139    f=  1.80165D-01    |proj g|=  1.48732D-03\n",
      "\n",
      "At iterate  140    f=  1.80159D-01    |proj g|=  1.20453D-03\n",
      "\n",
      "At iterate  141    f=  1.80144D-01    |proj g|=  9.37571D-04\n",
      "\n",
      "At iterate  142    f=  1.80117D-01    |proj g|=  3.03945D-03\n",
      "\n",
      "At iterate  143    f=  1.80080D-01    |proj g|=  1.93748D-03\n",
      "\n",
      "At iterate  144    f=  1.80024D-01    |proj g|=  7.57767D-03\n",
      "\n",
      "At iterate  145    f=  1.79984D-01    |proj g|=  5.50326D-03\n",
      "\n",
      "At iterate  146    f=  1.79854D-01    |proj g|=  5.11549D-03\n",
      "\n",
      "At iterate  147    f=  1.79831D-01    |proj g|=  1.20931D-02\n",
      "\n",
      "At iterate  148    f=  1.79814D-01    |proj g|=  1.11543D-02\n",
      "\n",
      "At iterate  149    f=  1.79764D-01    |proj g|=  1.41748D-03\n",
      "\n",
      "At iterate  150    f=  1.79760D-01    |proj g|=  1.56128D-03\n",
      "\n",
      "At iterate  151    f=  1.79751D-01    |proj g|=  1.02607D-03\n",
      "\n",
      "At iterate  152    f=  1.79708D-01    |proj g|=  6.12381D-03\n",
      "\n",
      "At iterate  153    f=  1.79687D-01    |proj g|=  2.75554D-03\n",
      "\n",
      "At iterate  154    f=  1.79666D-01    |proj g|=  3.53383D-03\n",
      "\n",
      "At iterate  155    f=  1.79658D-01    |proj g|=  4.60120D-03\n",
      "\n",
      "At iterate  156    f=  1.79619D-01    |proj g|=  5.78760D-03\n",
      "\n",
      "At iterate  157    f=  1.79580D-01    |proj g|=  6.69111D-03\n",
      "\n",
      "At iterate  158    f=  1.79566D-01    |proj g|=  5.16888D-03\n",
      "\n",
      "At iterate  159    f=  1.79544D-01    |proj g|=  4.54238D-03\n",
      "\n",
      "At iterate  160    f=  1.79524D-01    |proj g|=  1.55041D-03\n",
      "\n",
      "At iterate  161    f=  1.79510D-01    |proj g|=  1.04221D-03\n",
      "\n",
      "At iterate  162    f=  1.79490D-01    |proj g|=  7.62422D-04\n",
      "\n",
      "At iterate  163    f=  1.79471D-01    |proj g|=  1.48346D-03\n",
      "\n",
      "At iterate  164    f=  1.79465D-01    |proj g|=  2.57787D-03\n",
      "\n",
      "At iterate  165    f=  1.79457D-01    |proj g|=  9.09881D-04\n",
      "\n",
      "At iterate  166    f=  1.79451D-01    |proj g|=  9.68310D-04\n",
      "\n",
      "At iterate  167    f=  1.79411D-01    |proj g|=  5.41229D-03\n",
      "\n",
      "At iterate  168    f=  1.79398D-01    |proj g|=  1.07019D-03\n",
      "\n",
      "At iterate  169    f=  1.79387D-01    |proj g|=  1.65821D-03\n",
      "\n",
      "At iterate  170    f=  1.79378D-01    |proj g|=  1.13198D-03\n",
      "\n",
      "At iterate  171    f=  1.79367D-01    |proj g|=  5.76359D-04\n",
      "\n",
      "At iterate  172    f=  1.79347D-01    |proj g|=  5.90726D-04\n",
      "\n",
      "At iterate  173    f=  1.79343D-01    |proj g|=  1.03778D-03\n",
      "\n",
      "At iterate  174    f=  1.79322D-01    |proj g|=  8.84306D-04\n",
      "\n",
      "At iterate  175    f=  1.79281D-01    |proj g|=  4.72736D-03\n",
      "\n",
      "At iterate  176    f=  1.79264D-01    |proj g|=  7.68389D-03\n",
      "\n",
      "At iterate  177    f=  1.79205D-01    |proj g|=  4.65255D-03\n",
      "\n",
      "At iterate  178    f=  1.79178D-01    |proj g|=  6.84681D-03\n",
      "\n",
      "At iterate  179    f=  1.79171D-01    |proj g|=  3.01473D-03\n",
      "\n",
      "At iterate  180    f=  1.79165D-01    |proj g|=  2.49628D-03\n",
      "\n",
      "At iterate  181    f=  1.79145D-01    |proj g|=  2.26410D-03\n",
      "\n",
      "At iterate  182    f=  1.79090D-01    |proj g|=  6.82980D-03\n",
      "\n",
      "At iterate  183    f=  1.79067D-01    |proj g|=  3.97849D-03\n",
      "\n",
      "At iterate  184    f=  1.79049D-01    |proj g|=  7.50714D-03\n",
      "\n",
      "At iterate  185    f=  1.79034D-01    |proj g|=  3.21451D-03\n",
      "\n",
      "At iterate  186    f=  1.79029D-01    |proj g|=  1.62935D-03\n",
      "\n",
      "At iterate  187    f=  1.79020D-01    |proj g|=  7.79683D-04\n",
      "\n",
      "At iterate  188    f=  1.79011D-01    |proj g|=  7.14301D-03\n",
      "\n",
      "At iterate  189    f=  1.78998D-01    |proj g|=  4.62985D-03\n",
      "\n",
      "At iterate  190    f=  1.78988D-01    |proj g|=  3.11325D-04\n",
      "\n",
      "At iterate  191    f=  1.78987D-01    |proj g|=  9.00801D-04\n",
      "\n",
      "At iterate  192    f=  1.78986D-01    |proj g|=  9.72584D-04\n",
      "\n",
      "At iterate  193    f=  1.78982D-01    |proj g|=  4.57702D-04\n",
      "\n",
      "At iterate  194    f=  1.78979D-01    |proj g|=  8.11688D-04\n",
      "\n",
      "At iterate  195    f=  1.78962D-01    |proj g|=  2.26036D-03\n",
      "\n",
      "At iterate  196    f=  1.78943D-01    |proj g|=  3.84859D-03\n",
      "\n",
      "At iterate  197    f=  1.78918D-01    |proj g|=  4.76420D-03\n",
      "\n",
      "At iterate  198    f=  1.78894D-01    |proj g|=  1.14101D-03\n",
      "\n",
      "At iterate  199    f=  1.78879D-01    |proj g|=  2.51096D-03\n",
      "\n",
      "At iterate  200    f=  1.78873D-01    |proj g|=  6.53823D-04\n",
      "\n",
      "At iterate  201    f=  1.78863D-01    |proj g|=  1.48271D-03\n",
      "\n",
      "At iterate  202    f=  1.78845D-01    |proj g|=  1.58687D-03\n",
      "\n",
      "At iterate  203    f=  1.78841D-01    |proj g|=  4.82029D-03\n",
      "\n",
      "At iterate  204    f=  1.78833D-01    |proj g|=  2.78167D-03\n",
      "\n",
      "At iterate  205    f=  1.78824D-01    |proj g|=  1.63735D-03\n",
      "\n",
      "At iterate  206    f=  1.78807D-01    |proj g|=  1.07843D-03\n",
      "\n",
      "At iterate  207    f=  1.78796D-01    |proj g|=  1.38876D-03\n",
      "\n",
      "At iterate  208    f=  1.78781D-01    |proj g|=  4.10572D-03\n",
      "\n",
      "At iterate  209    f=  1.78753D-01    |proj g|=  5.06319D-03\n",
      "\n",
      "At iterate  210    f=  1.78709D-01    |proj g|=  1.36567D-02\n",
      "\n",
      "At iterate  211    f=  1.78601D-01    |proj g|=  3.80578D-03\n",
      "\n",
      "At iterate  212    f=  1.78547D-01    |proj g|=  6.56494D-03\n",
      "\n",
      "At iterate  213    f=  1.78451D-01    |proj g|=  4.14122D-03\n",
      "\n",
      "At iterate  214    f=  1.78432D-01    |proj g|=  3.19162D-03\n",
      "\n",
      "At iterate  215    f=  1.78355D-01    |proj g|=  1.17427D-02\n",
      "\n",
      "At iterate  216    f=  1.78229D-01    |proj g|=  7.86373D-03\n",
      "\n",
      "At iterate  217    f=  1.78170D-01    |proj g|=  2.76636D-03\n",
      "\n",
      "At iterate  218    f=  1.78133D-01    |proj g|=  9.64599D-03\n",
      "\n",
      "At iterate  219    f=  1.78084D-01    |proj g|=  1.08978D-02\n",
      "\n",
      "At iterate  220    f=  1.77979D-01    |proj g|=  8.30484D-03\n",
      "\n",
      "At iterate  221    f=  1.77892D-01    |proj g|=  4.64092D-03\n",
      "\n",
      "At iterate  222    f=  1.77859D-01    |proj g|=  5.06836D-03\n",
      "\n",
      "At iterate  223    f=  1.77775D-01    |proj g|=  6.30563D-03\n",
      "\n",
      "At iterate  224    f=  1.77716D-01    |proj g|=  2.81463D-03\n",
      "\n",
      "At iterate  225    f=  1.77660D-01    |proj g|=  7.91945D-03\n",
      "\n",
      "At iterate  226    f=  1.77613D-01    |proj g|=  2.79836D-03\n",
      "\n",
      "At iterate  227    f=  1.77589D-01    |proj g|=  3.18640D-03\n",
      "\n",
      "At iterate  228    f=  1.77555D-01    |proj g|=  3.05316D-03\n",
      "\n",
      "At iterate  229    f=  1.77513D-01    |proj g|=  1.68264D-03\n",
      "\n",
      "At iterate  230    f=  1.77497D-01    |proj g|=  1.70293D-03\n",
      "\n",
      "At iterate  231    f=  1.77480D-01    |proj g|=  1.01433D-03\n",
      "\n",
      "At iterate  232    f=  1.77466D-01    |proj g|=  3.06545D-04\n",
      "\n",
      "At iterate  233    f=  1.77461D-01    |proj g|=  7.70136D-04\n",
      "\n",
      "At iterate  234    f=  1.77456D-01    |proj g|=  1.03830D-03\n",
      "\n",
      "At iterate  235    f=  1.77449D-01    |proj g|=  6.38011D-04\n",
      "\n",
      "At iterate  236    f=  1.77443D-01    |proj g|=  2.47701D-04\n",
      "\n",
      "At iterate  237    f=  1.77439D-01    |proj g|=  8.78413D-04\n",
      "\n",
      "At iterate  238    f=  1.77427D-01    |proj g|=  4.44394D-04\n",
      "\n",
      "At iterate  239    f=  1.77423D-01    |proj g|=  2.12395D-03\n",
      "\n",
      "At iterate  240    f=  1.77415D-01    |proj g|=  1.65524D-03\n",
      "\n",
      "At iterate  241    f=  1.77407D-01    |proj g|=  3.12001D-03\n",
      "\n",
      "At iterate  242    f=  1.77401D-01    |proj g|=  5.82482D-04\n",
      "\n",
      "At iterate  243    f=  1.77400D-01    |proj g|=  5.17859D-04\n",
      "\n",
      "At iterate  244    f=  1.77398D-01    |proj g|=  5.44303D-04\n",
      "\n",
      "At iterate  245    f=  1.77393D-01    |proj g|=  1.10746D-03\n",
      "\n",
      "At iterate  246    f=  1.77389D-01    |proj g|=  8.05694D-04\n",
      "\n",
      "At iterate  247    f=  1.77383D-01    |proj g|=  6.71394D-04\n",
      "\n",
      "At iterate  248    f=  1.77365D-01    |proj g|=  2.41005D-03\n",
      "\n",
      "At iterate  249    f=  1.77345D-01    |proj g|=  3.54845D-03\n",
      "\n",
      "At iterate  250    f=  1.77300D-01    |proj g|=  4.11491D-03\n",
      "\n",
      "At iterate  251    f=  1.77285D-01    |proj g|=  4.42332D-03\n",
      "\n",
      "At iterate  252    f=  1.77266D-01    |proj g|=  6.97059D-03\n",
      "\n",
      "At iterate  253    f=  1.77226D-01    |proj g|=  9.84848D-03\n",
      "\n",
      "At iterate  254    f=  1.77174D-01    |proj g|=  2.19210D-03\n",
      "\n",
      "At iterate  255    f=  1.77142D-01    |proj g|=  1.68312D-03\n",
      "\n",
      "At iterate  256    f=  1.77130D-01    |proj g|=  2.22209D-03\n",
      "\n",
      "At iterate  257    f=  1.77110D-01    |proj g|=  2.56348D-03\n",
      "\n",
      "At iterate  258    f=  1.77101D-01    |proj g|=  1.76863D-03\n",
      "\n",
      "At iterate  259    f=  1.77075D-01    |proj g|=  1.16767D-03\n",
      "\n",
      "At iterate  260    f=  1.77012D-01    |proj g|=  1.03008D-03\n",
      "\n",
      "At iterate  261    f=  1.76946D-01    |proj g|=  3.80000D-03\n",
      "\n",
      "At iterate  262    f=  1.76881D-01    |proj g|=  2.76035D-03\n",
      "\n",
      "At iterate  263    f=  1.76850D-01    |proj g|=  6.91613D-04\n",
      "\n",
      "At iterate  264    f=  1.76771D-01    |proj g|=  3.96853D-03\n",
      "\n",
      "At iterate  265    f=  1.76734D-01    |proj g|=  1.17159D-03\n",
      "\n",
      "At iterate  266    f=  1.76704D-01    |proj g|=  4.16872D-04\n",
      "\n",
      "At iterate  267    f=  1.76687D-01    |proj g|=  1.11021D-03\n",
      "\n",
      "At iterate  268    f=  1.76676D-01    |proj g|=  9.12705D-04\n",
      "\n",
      "At iterate  269    f=  1.76668D-01    |proj g|=  2.37412D-03\n",
      "\n",
      "At iterate  270    f=  1.76645D-01    |proj g|=  4.79576D-04\n",
      "\n",
      "At iterate  271    f=  1.76627D-01    |proj g|=  1.23322D-03\n",
      "\n",
      "At iterate  272    f=  1.76603D-01    |proj g|=  2.56064D-03\n",
      "\n",
      "At iterate  273    f=  1.76581D-01    |proj g|=  1.19973D-03\n",
      "\n",
      "At iterate  274    f=  1.76550D-01    |proj g|=  4.31111D-03\n",
      "\n",
      "At iterate  275    f=  1.76494D-01    |proj g|=  9.61114D-04\n",
      "\n",
      "At iterate  276    f=  1.76473D-01    |proj g|=  6.18160D-04\n",
      "\n",
      "At iterate  277    f=  1.76458D-01    |proj g|=  6.16995D-04\n",
      "\n",
      "At iterate  278    f=  1.76448D-01    |proj g|=  2.18322D-03\n",
      "\n",
      "At iterate  279    f=  1.76426D-01    |proj g|=  1.83077D-03\n",
      "\n",
      "At iterate  280    f=  1.76392D-01    |proj g|=  5.72826D-03\n",
      "\n",
      "At iterate  281    f=  1.76340D-01    |proj g|=  3.35160D-03\n",
      "\n",
      "At iterate  282    f=  1.76266D-01    |proj g|=  3.29297D-03\n",
      "\n",
      "At iterate  283    f=  1.76207D-01    |proj g|=  1.42123D-03\n",
      "\n",
      "At iterate  284    f=  1.76162D-01    |proj g|=  1.17838D-03\n",
      "\n",
      "At iterate  285    f=  1.76131D-01    |proj g|=  4.64094D-04\n",
      "\n",
      "At iterate  286    f=  1.76124D-01    |proj g|=  1.63902D-03\n",
      "\n",
      "At iterate  287    f=  1.76112D-01    |proj g|=  5.14940D-04\n",
      "\n",
      "At iterate  288    f=  1.76101D-01    |proj g|=  2.98498D-04\n",
      "\n",
      "At iterate  289    f=  1.76082D-01    |proj g|=  7.09991D-04\n",
      "\n",
      "At iterate  290    f=  1.76055D-01    |proj g|=  1.15332D-03\n",
      "\n",
      "At iterate  291    f=  1.76043D-01    |proj g|=  8.91668D-04\n",
      "\n",
      "At iterate  292    f=  1.76041D-01    |proj g|=  6.47367D-04\n",
      "\n",
      "At iterate  293    f=  1.76036D-01    |proj g|=  2.37274D-04\n",
      "\n",
      "At iterate  294    f=  1.76034D-01    |proj g|=  2.79942D-04\n",
      "\n",
      "At iterate  295    f=  1.76029D-01    |proj g|=  5.42734D-04\n",
      "\n",
      "At iterate  296    f=  1.76018D-01    |proj g|=  4.38900D-04\n",
      "\n",
      "At iterate  297    f=  1.76015D-01    |proj g|=  2.19500D-03\n",
      "\n",
      "At iterate  298    f=  1.75990D-01    |proj g|=  1.07217D-03\n",
      "\n",
      "At iterate  299    f=  1.75962D-01    |proj g|=  1.80753D-03\n",
      "\n",
      "At iterate  300    f=  1.75930D-01    |proj g|=  2.78166D-03\n",
      "\n",
      "At iterate  301    f=  1.75868D-01    |proj g|=  2.35571D-03\n",
      "\n",
      "At iterate  302    f=  1.75825D-01    |proj g|=  8.87319D-04\n",
      "\n",
      "At iterate  303    f=  1.75779D-01    |proj g|=  2.67472D-03\n",
      "\n",
      "At iterate  304    f=  1.75720D-01    |proj g|=  4.08999D-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17488151710303415"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 4, 2), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    verbose=True,\n",
    "                     learning_rate_init=.001,\n",
    "\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "mlp.score(x_train, y_train)\n",
    "mlp.loss_\n",
    "\n",
    "#fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2978f5-1b5f-417d-90ed-9ae26c08512f",
   "metadata": {},
   "source": [
    "#### best parameters & testing on holdout set\n",
    "the disease is very rare, in fact, few patients in the sample even have it. We shouldd therefore aim to minimize false negatives, so we do not miss anyone having it. Therefore, we want to maximize recall.\n",
    "\n",
    "in training, the learning rate never made a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2230926-15e6-4335-baf6-111b0462946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy, 3d best recall\n",
      "\n",
      "At iterate  305    f=  1.75671D-01    |proj g|=  1.89624D-03\n",
      "\n",
      "At iterate  306    f=  1.75630D-01    |proj g|=  4.08641D-03\n",
      "\n",
      "At iterate  307    f=  1.75555D-01    |proj g|=  8.62967D-04\n",
      "\n",
      "At iterate  308    f=  1.75533D-01    |proj g|=  1.99795D-03\n",
      "\n",
      "At iterate  309    f=  1.75485D-01    |proj g|=  3.35670D-03\n",
      "\n",
      "At iterate  310    f=  1.75444D-01    |proj g|=  3.13307D-03\n",
      "\n",
      "At iterate  311    f=  1.75397D-01    |proj g|=  3.56955D-03\n",
      "\n",
      "At iterate  312    f=  1.75298D-01    |proj g|=  8.51299D-04\n",
      "\n",
      "At iterate  313    f=  1.75258D-01    |proj g|=  3.25341D-03\n",
      "\n",
      "At iterate  314    f=  1.75218D-01    |proj g|=  5.23578D-04\n",
      "\n",
      "At iterate  315    f=  1.75203D-01    |proj g|=  3.81703D-04\n",
      "\n",
      "At iterate  316    f=  1.75195D-01    |proj g|=  8.03955D-04\n",
      "\n",
      "At iterate  317    f=  1.75190D-01    |proj g|=  5.94270D-04\n",
      "\n",
      "At iterate  318    f=  1.75181D-01    |proj g|=  7.11230D-04\n",
      "\n",
      "At iterate  319    f=  1.75161D-01    |proj g|=  4.23975D-04\n",
      "\n",
      "At iterate  320    f=  1.75130D-01    |proj g|=  1.17499D-03\n",
      "\n",
      "At iterate  321    f=  1.75109D-01    |proj g|=  1.33780D-03\n",
      "\n",
      "At iterate  322    f=  1.75096D-01    |proj g|=  1.37688D-03\n",
      "\n",
      "At iterate  323    f=  1.75075D-01    |proj g|=  1.45342D-03\n",
      "\n",
      "At iterate  324    f=  1.75070D-01    |proj g|=  1.57490D-03\n",
      "\n",
      "At iterate  325    f=  1.75046D-01    |proj g|=  7.23950D-04\n",
      "\n",
      "At iterate  326    f=  1.75041D-01    |proj g|=  3.03923D-04\n",
      "\n",
      "At iterate  327    f=  1.75034D-01    |proj g|=  3.97454D-04\n",
      "\n",
      "At iterate  328    f=  1.75014D-01    |proj g|=  5.98443D-04\n",
      "\n",
      "At iterate  329    f=  1.75004D-01    |proj g|=  6.03338D-04\n",
      "\n",
      "At iterate  330    f=  1.74990D-01    |proj g|=  6.51027D-04\n",
      "\n",
      "At iterate  331    f=  1.74981D-01    |proj g|=  4.55753D-04\n",
      "\n",
      "At iterate  332    f=  1.74973D-01    |proj g|=  5.23144D-04\n",
      "\n",
      "At iterate  333    f=  1.74966D-01    |proj g|=  2.94009D-04\n",
      "\n",
      "At iterate  334    f=  1.74959D-01    |proj g|=  3.52986D-04\n",
      "\n",
      "At iterate  335    f=  1.74950D-01    |proj g|=  5.21054D-04\n",
      "\n",
      "At iterate  336    f=  1.74939D-01    |proj g|=  5.25269D-04\n",
      "\n",
      "At iterate  337    f=  1.74932D-01    |proj g|=  3.90374D-04\n",
      "\n",
      "At iterate  338    f=  1.74921D-01    |proj g|=  1.55414D-04\n",
      "\n",
      "At iterate  339    f=  1.74913D-01    |proj g|=  1.46807D-04\n",
      "\n",
      "At iterate  340    f=  1.74910D-01    |proj g|=  4.91614D-04\n",
      "\n",
      "At iterate  341    f=  1.74906D-01    |proj g|=  4.11799D-04\n",
      "\n",
      "At iterate  342    f=  1.74899D-01    |proj g|=  3.51299D-04\n",
      "\n",
      "At iterate  343    f=  1.74891D-01    |proj g|=  1.72668D-04\n",
      "\n",
      "At iterate  344    f=  1.74882D-01    |proj g|=  9.63245D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   77    344    438      1     0     0   9.632D-05   1.749D-01\n",
      "  F =  0.17488151710303415     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "(6, 4) relu lbfgs\n",
      "Accuracy balanced: 0.7666666666666666\n",
      "Recall balanced: 0.8333333333333334\n",
      "------\n",
      "best recall, 2nd best accuracy\n",
      "(6, 4, 2) logistic lbfgs\n",
      "Accuracy balanced: 0.8629629629629629\n",
      "Recall balanced: 0.8809523809523809\n",
      "------\n",
      "3d best accuracy\n",
      "(6, 2) logistic lbfgs\n",
      "Accuracy balanced: 0.8814814814814815\n",
      "Recall balanced: 0.9047619047619048\n",
      "------\n",
      "2nd best recall\n",
      "(2) tanh lbfgs\n",
      "Accuracy balanced: 0.8333333333333333\n",
      "Recall balanced: 0.8809523809523809\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "x_test = x_biomed_test\n",
    "y_test = y_biomed_test\n",
    "\n",
    "\n",
    "print(\"best accuracy, 3d best recall\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 4), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"relu\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(6, 4)\", \"relu\", \"lbfgs\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Recall balanced:\", recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "print(\"best recall, 2nd best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 4, 2), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(6, 4, 2)\", \"logistic\", \"lbfgs\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Recall balanced:\", recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "print(\"3d best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (6, 2), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(6, 2)\", \"logistic\", \"lbfgs\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Recall balanced:\", recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "print(\"2nd best recall\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (2), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"tanh\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(2)\", \"tanh\", \"lbfgs\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Recall balanced:\", recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fbafc23-d9b0-44a6-b6b6-dbb2bfa901ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.5388797219292576\n",
      "recall 0.9333333333333333\n",
      "[[1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0\n",
      "  1 0 0 0 0 1]\n",
      " [1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0\n",
      "  1 1 1 1 0 1]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   0   1\n",
       "actual           \n",
       "1           0  15\n",
       "0          13  14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other good example\n",
    "x_train = x_biomed_train\n",
    "y_train = y_biomed_train\n",
    "# make a model\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (4), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"tanh\", \n",
    "                    solver=\"sgd\", \n",
    "                    learning_rate = \"invscaling\",\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "print(\"f1:\", cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"f1_weighted\").mean())\n",
    "print(\"recall\", cross_val_score(mlp, x_train, y_train, cv=10, scoring=\"recall\").mean())\n",
    "\n",
    "mlp.fit(x_train, y_train)\n",
    "print(np.array([y_biomed_test, mlp.predict(x_biomed_test)]))\n",
    "\n",
    "print()\n",
    "# confusion matrix\n",
    "pd.crosstab(y_biomed_test, mlp.predict(x_biomed_test), colnames=[\"predicted\"], rownames=[\"actual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b47d4-2b55-4c54-8f2e-b5a01a5e717d",
   "metadata": {},
   "source": [
    "### MLP: fertility\n",
    "class labels: 0 is \"normal\", 1 is \"altered\"\n",
    "\n",
    "intuition for evaluation: it's maybe better to falsely inform people that they are fertile, even though they may not be, than the other way around, telling potentially fertile people they aren't fertile. People failing while trying for a baby is common and typically less of a big deal than people accidentally getting pregnant believing they are unable to and also not wanting to. In other words, unwanted pregnancy with our model at fault would be the bigger issue than giving false hopes. On the other hand, the more realistic setting of this model in action is that it would advise anyone, where fertility could potentially be altered to go see a physician, so the model would not ever be blamed for an unwanted pregnancy anyways.\n",
    "\"Normal fertility\" corresponds with 0 in our class labels, therefore avoiding mistakingly classifying a patient as having \"altered fertility\" means avoiding false positives, therefore we aim for high precision over recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d50dd86a-7ca1-42c1-b653-b4d8e88c9e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9375 0.875  0.875  0.8125 0.75  ]\n",
      "[0.92816092 0.81666667 0.81666667 0.78448276 0.75      ]\n"
     ]
    }
   ],
   "source": [
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "learning_rate_init = 0.001 # default 0.001\n",
    "\n",
    "x_train = x_fert_train\n",
    "y_train = y_fert_train\n",
    "\n",
    "\n",
    "hidden_layers = (8,6,1)\n",
    "hidden_layers = (21)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = hidden_layers, \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = activation_functions[1], \n",
    "                    solver=solvers[-1], \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "\n",
    "# cross validating\n",
    "# first param is the model incl its params, second is features, \n",
    "# third is class labels, cv is the k of k-fold-CV, scoring is the wanted scores\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=5, scoring=\"accuracy\"))\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=5, scoring=\"f1_weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca0d0d-8884-4743-b78f-2a38e1a9b105",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48ad414e-979d-47ff-b74c-e607c4fdab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing params for fertility\n",
    "fertility_results = pd.DataFrame(columns=[\"classifier\", \"balanced_accuracy\", \n",
    "                                       \"f1_weighted\", \"recall\", \n",
    "                                       \"precision\", \"time_taken\", \"activation_function\", \n",
    "                                       \"solver\", \"learning_rate\", \n",
    "                                       \"hidden_layer\"])\n",
    "# the scores we want\n",
    "scoring = {'balanced_accuracy': 'balanced_accuracy',\n",
    "           'f1_weighted': 'f1_weighted',\n",
    "           'precision_weighted': 'precision_weighted',\n",
    "           'recall_weighted': 'recall_weighted'}\n",
    "\n",
    "# performing cross-fold validation on the training data to evaluate best parameters\n",
    "\n",
    "# filter out warnings (not sure if this is a good idea)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "x_train = x_fert_train\n",
    "y_train = y_fert_train\n",
    "\n",
    "hidden_layers = [\n",
    "    (2),\n",
    "    (10),\n",
    "    (21),\n",
    "    (10, 5),\n",
    "    (10, 10),\n",
    "    (21, 2),\n",
    "    (21, 10),\n",
    "    (21, 10, 2),\n",
    "]\n",
    "\n",
    "# cross-validation\n",
    "k = 5\n",
    "\n",
    "# running number to count iterations/permutations\n",
    "i = 0\n",
    "\n",
    "\n",
    "# only do the computation, if the following flag is true\n",
    "# it takes an hour or so to compute this, not necessary\n",
    "if True:\n",
    "    # iterate through all parameter permutations\n",
    "    # save accuracy, f1, precisiona and recall\n",
    "    for activation_function in activation_functions:\n",
    "        for solver in solvers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for hidden_layer in hidden_layers:\n",
    "                    \n",
    "                    # make a model\n",
    "                    mlp = MLPClassifier(hidden_layer_sizes = hidden_layer, \n",
    "                                        max_iter=300, # epochs\n",
    "                                        activation = activation_function, \n",
    "                                        solver=solver, \n",
    "                                        learning_rate = learning_rate,\n",
    "                                        learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "\n",
    "                    # cross_validate() returns a dictionary with results\n",
    "                    # cv = k for f-fold cross-validation\n",
    "                    cv_results = cross_validate(mlp, x_train, y_train, cv=k, scoring=scoring, return_train_score=True)\n",
    "                    \n",
    "                    # extract the result values and take the mean of the 5 iterations\n",
    "                    fit_time = cv_results[\"fit_time\"].mean()\n",
    "                    balanced_accuracy = cv_results[\"test_balanced_accuracy\"].mean()\n",
    "                    f1_weighted = cv_results[\"test_f1_weighted\"].mean()\n",
    "                    recall = cv_results[\"test_recall_weighted\"].mean()\n",
    "                    precision = cv_results[\"test_precision_weighted\"].mean()\n",
    "                    \n",
    "                    # print out the running number, the accuracy and the parameters\n",
    "                    print(i, \"- acc:\", balanced_accuracy, \"-, time:\",  fit_time, end=\"\\r\")\n",
    "                    \n",
    "                    # save everything\n",
    "                    fertility_results = pd.concat([fertility_results, pd.DataFrame({\n",
    "                        \"classifier\": \"mlp\",\n",
    "                        \"balanced_accuracy\": [balanced_accuracy],\n",
    "                        \"f1_weighted\": [f1_weighted],\n",
    "                        \"recall\": [recall],\n",
    "                        \"precision\": [precision],\n",
    "                        \"time_taken\": fit_time,\n",
    "                        \"activation_function\": activation_function,\n",
    "                        \"solver\": solver,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"hidden_layer\": str(hidden_layer)                        \n",
    "                    })], ignore_index=True)\n",
    "                    i += 1;\n",
    " \n",
    "    display(fertility_results)\n",
    "    \n",
    "    # saving the results as a pickle\n",
    "    with open('data/fertility/fertility_results_unscaled.pickle', 'wb') as f:\n",
    "        pickle.dump(fertility_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad0ddab3-0db8-4a88-a6c3-4bf7c799f06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [classifier, balanced_accuracy, f1_weighted, recall, precision, time_taken, activation_function, solver, learning_rate, hidden_layer]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertility_results[fertility_results.hidden_layer==\"2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6f1f9-cfaf-4d7c-988b-c9288361282b",
   "metadata": {},
   "source": [
    "First training run mit k=10\n",
    "\n",
    "Wow, the results so far are pretty bad. F1 scores are looking ok-ish, but accuracy never even reaches 0.7. Precision is quite low, meaning we get heaps of false positives. Upon crying over these results, we remembered that the training data only contains 80 samples, so doing 10-fold cross-validation might have been a mistake. Now rerunning with k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8044a056-0ed6-42f4-b886-8a684996c25a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.747264</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.858598</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.652808</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.838694</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(21, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.816330</td>\n",
       "      <td>0.039305</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.816330</td>\n",
       "      <td>0.027684</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.816330</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.807928</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.813754</td>\n",
       "      <td>0.035992</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(10, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.807928</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.813754</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(10, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.807928</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.813754</td>\n",
       "      <td>0.037799</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(10, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.278273</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.893571</td>\n",
       "      <td>0.079978</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(10, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.127086</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(21, 10, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier  balanced_accuracy  f1_weighted  recall  precision  time_taken  \\\n",
       "32         mlp           0.700000     0.747264  0.7000   0.858598    0.011627   \n",
       "110        mlp           0.635714     0.652808  0.5875   0.838694    0.115512   \n",
       "0          mlp           0.600000     0.817196  0.8250   0.816330    0.039305   \n",
       "8          mlp           0.600000     0.817196  0.8250   0.816330    0.027684   \n",
       "16         mlp           0.600000     0.817196  0.8250   0.816330    0.027929   \n",
       "19         mlp           0.592857     0.807928  0.8125   0.813754    0.035992   \n",
       "11         mlp           0.592857     0.807928  0.8125   0.813754    0.042255   \n",
       "3          mlp           0.592857     0.807928  0.8125   0.813754    0.037799   \n",
       "179        mlp           0.585714     0.278273  0.2750   0.893571    0.079978   \n",
       "199        mlp           0.571429     0.830862  0.8500   0.818125    0.127086   \n",
       "\n",
       "    activation_function solver learning_rate hidden_layer  \n",
       "32             logistic    sgd    invscaling            2  \n",
       "110                tanh    sgd    invscaling     (21, 10)  \n",
       "0              logistic  lbfgs      constant            2  \n",
       "8              logistic  lbfgs    invscaling            2  \n",
       "16             logistic  lbfgs      adaptive            2  \n",
       "19             logistic  lbfgs      adaptive      (10, 5)  \n",
       "11             logistic  lbfgs    invscaling      (10, 5)  \n",
       "3              logistic  lbfgs      constant      (10, 5)  \n",
       "179                relu    sgd    invscaling      (10, 5)  \n",
       "199                relu   adam      constant  (21, 10, 2)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.800833</td>\n",
       "      <td>0.099973</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.800833</td>\n",
       "      <td>0.100424</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.800833</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.125675</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(21, 10, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.127235</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(21, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.128002</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(21, 10, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.127086</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(21, 10, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.125987</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(21, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.146762</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(21, 10, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.830862</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.129492</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(21, 10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier  balanced_accuracy  f1_weighted  recall  precision  time_taken  \\\n",
       "210        mlp           0.550000     0.838966  0.8875   0.800833    0.099973   \n",
       "202        mlp           0.550000     0.838966  0.8875   0.800833    0.100424   \n",
       "194        mlp           0.550000     0.838966  0.8875   0.800833    0.098712   \n",
       "215        mlp           0.571429     0.830862  0.8500   0.818125    0.125675   \n",
       "142        mlp           0.571429     0.830862  0.8500   0.818125    0.127235   \n",
       "207        mlp           0.571429     0.830862  0.8500   0.818125    0.128002   \n",
       "199        mlp           0.571429     0.830862  0.8500   0.818125    0.127086   \n",
       "126        mlp           0.571429     0.830862  0.8500   0.818125    0.125987   \n",
       "127        mlp           0.571429     0.830862  0.8500   0.818125    0.146762   \n",
       "134        mlp           0.571429     0.830862  0.8500   0.818125    0.129492   \n",
       "\n",
       "    activation_function solver learning_rate hidden_layer  \n",
       "210                relu   adam      adaptive           21  \n",
       "202                relu   adam    invscaling           21  \n",
       "194                relu   adam      constant           21  \n",
       "215                relu   adam      adaptive  (21, 10, 2)  \n",
       "142                tanh   adam      adaptive     (21, 10)  \n",
       "207                relu   adam    invscaling  (21, 10, 2)  \n",
       "199                relu   adam      constant  (21, 10, 2)  \n",
       "126                tanh   adam      constant     (21, 10)  \n",
       "127                tanh   adam      constant  (21, 10, 2)  \n",
       "134                tanh   adam    invscaling     (21, 10)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/fertility/fertility_results_k5.pickle', 'rb') as f:\n",
    "        fertility_results = pickle.load(f)\n",
    "\n",
    "display(fertility_results.sort_values(\"balanced_accuracy\", ascending=False).head(10))\n",
    "display(fertility_results.sort_values(\"f1_weighted\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e896d-c638-424c-b7db-fee749cc8c2e",
   "metadata": {},
   "source": [
    "accuracy is still isnt ascending over 0.7, but we got way higher precision this time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681e6e5-deaa-48af-aa19-e8f3160f2ed7",
   "metadata": {},
   "source": [
    "#### best params & testing\n",
    "here the learning rate DID make a difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d42b4e5-13ea-4242-8da4-1cfaf7794c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy\n",
      "(2) logistic sgd invscaling learning rate\n",
      "Accuracy balanced: 0.5833333333333333\n",
      "F1 balanced: 0.7189964157706094\n",
      "Precision balanced: 0.845054945054945\n",
      "------\n",
      "best f1 weighted and best precision\n",
      "(21) relu adam\n",
      "Accuracy balanced: 0.4444444444444444\n",
      "F1 balanced: 0.8\n",
      "Precision balanced: 0.8\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "x_train = x_fert_train\n",
    "y_train = y_fert_train\n",
    "x_test = x_fert_test\n",
    "y_test = y_fert_test\n",
    "\n",
    "print(\"best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (2), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"sgd\", \n",
    "                    learning_rate=\"invscaling\",\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(2)\", \"logistic\", \"sgd\", \"invscaling learning rate\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"F1 balanced:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"Precision balanced:\", precision_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "print(\"best f1 weighted and best precision\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (21), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"relu\", \n",
    "                    solver=\"adam\", \n",
    "                  random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "#pd.crosstab(y_biomed_test, y_pred, colnames=[\"predicted\"], rownames=[\"actual\"])\n",
    "print(\"(21)\", \"relu\", \"adam\")\n",
    "print(\"Accuracy balanced:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"F1 balanced:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"Precision balanced:\", precision_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6df787-d16a-436f-96bd-3415ef52c848",
   "metadata": {},
   "source": [
    "### MLP: reviews\n",
    "class labels are not binary, so we cannot use f1, recall or precision but rather have to rely on weighted accuracy\n",
    "\n",
    "following our rules of thumb, we should use few hidden layers with nodes between 50 and 10,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddd20017-ee67-49d8-9e8c-b370e597d208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>child_diseases</th>\n",
       "      <th>accident</th>\n",
       "      <th>surgery</th>\n",
       "      <th>hours_sitting</th>\n",
       "      <th>fall</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>winter</th>\n",
       "      <th>fever_never</th>\n",
       "      <th>fever_not_recent</th>\n",
       "      <th>fever_recent</th>\n",
       "      <th>smoking_daily</th>\n",
       "      <th>smoking_never</th>\n",
       "      <th>smoking_occasionally</th>\n",
       "      <th>alcohol_daily</th>\n",
       "      <th>alcohol_rarely_or_never</th>\n",
       "      <th>alcohol_several_daily</th>\n",
       "      <th>alcohol_several_weekly</th>\n",
       "      <th>alcohol_weekly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  child_diseases  accident  surgery  hours_sitting  fall  spring  \\\n",
       "35  0.78               0         0        1           0.38     0       0   \n",
       "13  0.81               0         1        1           0.38     1       0   \n",
       "21  0.75               0         1        1           0.25     1       0   \n",
       "26  0.67               0         1        0           0.38     1       0   \n",
       "50  0.67               0         1        0           0.19     0       1   \n",
       "..   ...             ...       ...      ...            ...   ...     ...   \n",
       "7   1.00               0         0        0           0.38     0       1   \n",
       "10  0.67               0         0        1           0.31     1       0   \n",
       "45  0.53               0         1        1           0.44     0       0   \n",
       "17  0.69               0         1        0           0.25     1       0   \n",
       "80  0.92               0         0        1           0.63     0       1   \n",
       "\n",
       "    summer  winter  fever_never  fever_not_recent  fever_recent  \\\n",
       "35       0       1            1                 0             0   \n",
       "13       0       0            0                 1             0   \n",
       "21       0       0            0                 1             0   \n",
       "26       0       0            0                 1             0   \n",
       "50       0       0            0                 1             0   \n",
       "..     ...     ...          ...               ...           ...   \n",
       "7        0       0            0                 1             0   \n",
       "10       0       0            0                 0             1   \n",
       "45       0       1            1                 0             0   \n",
       "17       0       0            0                 1             0   \n",
       "80       0       0            1                 0             0   \n",
       "\n",
       "    smoking_daily  smoking_never  smoking_occasionally  alcohol_daily  \\\n",
       "35              0              1                     0              0   \n",
       "13              0              1                     0              0   \n",
       "21              0              0                     1              0   \n",
       "26              0              1                     0              0   \n",
       "50              0              1                     0              0   \n",
       "..            ...            ...                   ...            ...   \n",
       "7               0              1                     0              0   \n",
       "10              0              0                     1              0   \n",
       "45              0              0                     1              0   \n",
       "17              0              1                     0              0   \n",
       "80              0              1                     0              0   \n",
       "\n",
       "    alcohol_rarely_or_never  alcohol_several_daily  alcohol_several_weekly  \\\n",
       "35                        0                      0                       1   \n",
       "13                        1                      0                       0   \n",
       "21                        0                      0                       1   \n",
       "26                        0                      0                       1   \n",
       "50                        0                      0                       0   \n",
       "..                      ...                    ...                     ...   \n",
       "7                         0                      0                       1   \n",
       "10                        0                      0                       0   \n",
       "45                        1                      0                       0   \n",
       "17                        0                      0                       0   \n",
       "80                        1                      0                       0   \n",
       "\n",
       "    alcohol_weekly  \n",
       "35               0  \n",
       "13               0  \n",
       "21               0  \n",
       "26               0  \n",
       "50               1  \n",
       "..             ...  \n",
       "7                0  \n",
       "10               1  \n",
       "45               0  \n",
       "17               1  \n",
       "80               0  \n",
       "\n",
       "[80 rows x 20 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6ebf340-3e6f-4397-b5a0-38950c63928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "\n",
    "# testing params for reviews\n",
    "reviews_results = pd.DataFrame(columns=[\"classifier\", \"balanced_accuracy\", \n",
    "                                       \"time_taken\", \"activation_function\", \n",
    "                                       \"solver\", \"learning_rate\", \n",
    "                                       \"hidden_layer\", \"iterations\"])\n",
    "# the scores we want\n",
    "# no point in checking for precision or recall\n",
    "# arguably, one may be worse than the other, but not for the sake of the research :D\n",
    "scoring = {'balanced_accuracy': 'balanced_accuracy'}\n",
    "\n",
    "# performing cross-fold validation on the training data to evaluate best parameters\n",
    "\n",
    "# filter out warnings (not sure if this is a good idea)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "activation_function = \"logistic\"\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\"]\n",
    "\n",
    "x_train = x_reviews_train\n",
    "y_train = y_reviews_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_layers = [\n",
    "    (50, 50, 50),\n",
    "    (200, 100, 50),\n",
    "    (1000, 1000),\n",
    "    (1000, 1000, 50),\n",
    "    (2000, 500, 50),\n",
    "#    (5000),\n",
    "#    (1000),\n",
    "#    (10000),\n",
    "]\n",
    "\n",
    "# cross-validation\n",
    "k = 10\n",
    "\n",
    "# running number to count iterations/permutations\n",
    "i = 0\n",
    "\n",
    "\n",
    "# only do the computation, if the following flag is true\n",
    "# it takes an hour or so to compute this, not necessary\n",
    "if True:\n",
    "    # iterate through all parameter permutations\n",
    "    # save accuracy, f1, precisiona and recall\n",
    "    for max_iter in [500, 800]:\n",
    "        for solver in solvers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for hidden_layer in hidden_layers:\n",
    "                    \n",
    "                    # make a model\n",
    "                    mlp = MLPClassifier(hidden_layer_sizes = hidden_layer, \n",
    "                                        max_iter=max_iter, # epochs\n",
    "                                        activation = activation_function, \n",
    "                                        solver=solver, \n",
    "                                        verbose=True,\n",
    "                                        learning_rate = learning_rate,\n",
    "                                        learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "\n",
    "                    # cross_validate() returns a dictionary with results\n",
    "                    # cv = k for f-fold cross-validation\n",
    "                    cv_results = cross_validate(mlp, x_train, y_train, cv=k, scoring=scoring, return_train_score=True)\n",
    "                    \n",
    "                    # extract the result values and take the mean of the k iterations\n",
    "                    fit_time = cv_results[\"fit_time\"].mean()\n",
    "                    balanced_accuracy = cv_results[\"test_balanced_accuracy\"].mean()\n",
    "                    \n",
    "                    # print out the running number, the accuracy and the parameters\n",
    "                    print(i, \"- acc:\", balanced_accuracy, \"-, time:\",  fit_time, end=\"\\r\")\n",
    "                    \n",
    "                    # save everything\n",
    "                    reviews_results = pd.concat([reviews_results, pd.DataFrame({\n",
    "                        \"classifier\": \"mlp\",\n",
    "                        \"balanced_accuracy\": [balanced_accuracy],\n",
    "                        \"time_taken\": fit_time,\n",
    "                        \"activation_function\": activation_function,\n",
    "                        \"solver\": solver,\n",
    "                        \"iterations\": max_iter,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"hidden_layer\": str(hidden_layer)                        \n",
    "                    })], ignore_index=True)\n",
    "                    i += 1;\n",
    " \n",
    "    display(reviews_results)\n",
    "    \n",
    "    # saving the results as a pickle\n",
    "    with open(f'data/reviews/reviews_results_k{k}_4.pickle', 'wb') as f:\n",
    "        pickle.dump(reviews_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "151dd1e6-ed3f-4a3f-98ce-2caf6bf154b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.740408</td>\n",
       "      <td>101.882982</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.686245</td>\n",
       "      <td>67.672742</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.657619</td>\n",
       "      <td>69.126942</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.611830</td>\n",
       "      <td>63.347642</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.505810</td>\n",
       "      <td>42.704505</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.251490</td>\n",
       "      <td>43.051773</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  balanced_accuracy  time_taken activation_function solver  \\\n",
       "1        mlp           0.740408  101.882982            logistic   adam   \n",
       "3        mlp           0.686245   67.672742                tanh   adam   \n",
       "5        mlp           0.657619   69.126942                relu   adam   \n",
       "0        mlp           0.611830   63.347642            logistic   adam   \n",
       "2        mlp           0.505810   42.704505                tanh   adam   \n",
       "4        mlp           0.251490   43.051773                relu   adam   \n",
       "\n",
       "  learning_rate hidden_layer  \n",
       "1      constant         1000  \n",
       "3      constant         1000  \n",
       "5      constant         1000  \n",
       "0      constant           50  \n",
       "2      constant           50  \n",
       "4      constant           50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.611830</td>\n",
       "      <td>71.385762</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.611830</td>\n",
       "      <td>84.956902</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.497667</td>\n",
       "      <td>204.181449</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.454939</td>\n",
       "      <td>152.379840</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.164449</td>\n",
       "      <td>132.227634</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.161449</td>\n",
       "      <td>165.899050</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  balanced_accuracy  time_taken activation_function solver  \\\n",
       "2        mlp           0.611830   71.385762            logistic   adam   \n",
       "5        mlp           0.611830   84.956902            logistic   adam   \n",
       "4        mlp           0.497667  204.181449            logistic    sgd   \n",
       "1        mlp           0.454939  152.379840            logistic    sgd   \n",
       "0        mlp           0.164449  132.227634            logistic  lbfgs   \n",
       "3        mlp           0.161449  165.899050            logistic  lbfgs   \n",
       "\n",
       "  learning_rate hidden_layer  \n",
       "2      constant           50  \n",
       "5      constant           50  \n",
       "4      constant           50  \n",
       "1      constant           50  \n",
       "0      constant           50  \n",
       "3      constant           50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.688497</td>\n",
       "      <td>166.714588</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.688497</td>\n",
       "      <td>150.525065</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  balanced_accuracy  time_taken activation_function solver  \\\n",
       "0        mlp           0.688497  166.714588            logistic   adam   \n",
       "1        mlp           0.688497  150.525065            logistic   adam   \n",
       "\n",
       "  learning_rate  hidden_layer iterations  \n",
       "0      constant  (1000, 1000)        500  \n",
       "1      constant  (1000, 1000)        800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.688497</td>\n",
       "      <td>126.050256</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.688497</td>\n",
       "      <td>145.618657</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>1628.143984</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(2000, 500, 50)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>1611.926593</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(2000, 500, 50)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.423150</td>\n",
       "      <td>576.500537</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000, 50)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.423150</td>\n",
       "      <td>581.137089</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(1000, 1000, 50)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.348694</td>\n",
       "      <td>207.914831</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(200, 100, 50)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.348694</td>\n",
       "      <td>227.487648</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(200, 100, 50)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>105.945277</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>131.797761</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  balanced_accuracy   time_taken activation_function solver  \\\n",
       "2        mlp           0.688497   126.050256            logistic   adam   \n",
       "7        mlp           0.688497   145.618657            logistic   adam   \n",
       "4        mlp           0.463415  1628.143984            logistic   adam   \n",
       "9        mlp           0.463415  1611.926593            logistic   adam   \n",
       "3        mlp           0.423150   576.500537            logistic   adam   \n",
       "8        mlp           0.423150   581.137089            logistic   adam   \n",
       "1        mlp           0.348694   207.914831            logistic   adam   \n",
       "6        mlp           0.348694   227.487648            logistic   adam   \n",
       "0        mlp           0.266429   105.945277            logistic   adam   \n",
       "5        mlp           0.261408   131.797761            logistic   adam   \n",
       "\n",
       "  learning_rate      hidden_layer iterations  \n",
       "2      constant      (1000, 1000)        500  \n",
       "7      constant      (1000, 1000)        800  \n",
       "4      constant   (2000, 500, 50)        500  \n",
       "9      constant   (2000, 500, 50)        800  \n",
       "3      constant  (1000, 1000, 50)        500  \n",
       "8      constant  (1000, 1000, 50)        800  \n",
       "1      constant    (200, 100, 50)        500  \n",
       "6      constant    (200, 100, 50)        800  \n",
       "0      constant      (50, 50, 50)        500  \n",
       "5      constant      (50, 50, 50)        800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the saved results\n",
    "with open('data/reviews/reviews_results_k10.pickle', 'rb') as handle:\n",
    "    reviews_results_1 = pickle.load(handle)\n",
    "display(reviews_results_1.sort_values(\"balanced_accuracy\", ascending=False))\n",
    "\n",
    "# loading the saved results\n",
    "with open('data/reviews/reviews_results_k10_2.pickle', 'rb') as handle:\n",
    "    reviews_results_2 = pickle.load(handle)\n",
    "display(reviews_results_2.sort_values(\"balanced_accuracy\", ascending=False))\n",
    "\n",
    "# loading the saved results\n",
    "with open('data/reviews/reviews_results_k10_3.pickle', 'rb') as handle:\n",
    "    reviews_results_3 = pickle.load(handle)\n",
    "display(reviews_results_3.sort_values(\"balanced_accuracy\", ascending=False))\n",
    "\n",
    "# loading the saved results\n",
    "with open('data/reviews/reviews_results_k10_4.pickle', 'rb') as handle:\n",
    "    reviews_results_4 = pickle.load(handle)\n",
    "display(reviews_results_4.sort_values(\"balanced_accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e10fc-8e18-4cf5-a0e6-e94d833dde47",
   "metadata": {},
   "source": [
    "#### what are the best params??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3edc64f6-387e-437b-9bcd-fac0b0390756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n"
     ]
    }
   ],
   "source": [
    "# save results for kaggle\n",
    "x_train = x_reviews_train\n",
    "y_train = y_reviews_train\n",
    "\n",
    "\n",
    "x_test = x_reviews_test\n",
    "y_test = y_fert_test\n",
    "\n",
    "print(\"model 1\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (50), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", # acc to sklearn logistic is best for big datasets\n",
    "                    solver=\"adam\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": y_test, \"Class\": mlp.predict(x_test)})\n",
    "y_pred.to_csv(\"data/reviews/reviews_pred_mlp1.csv\", index=False)\n",
    "print(\"model 1: logistic, adam, (50)\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"model 2\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (500), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", # acc to sklearn logistic is best for big datasets\n",
    "                    solver=\"adam\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": y_test, \"Class\": mlp.predict(x_test)})\n",
    "y_pred.to_csv(\"data/reviews/reviews_pred_mlp2.csv\", index=False)\n",
    "print(\"model 2: logistic, adam, (500)\")\n",
    "print(\"model 3\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (5000), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", # acc to sklearn logistic is best for big datasets\n",
    "                    solver=\"adam\", \n",
    "                    verbose=True,\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": y_test, \"Class\": mlp.predict(x_test)})\n",
    "y_pred.to_csv(\"data/reviews/reviews_pred_mlp3.csv\", index=False)\n",
    "print(\"model 3: logistic, adam, (5000)\")\n",
    "print(\"model 4\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (1000, 1000), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", # acc to sklearn logistic is best for big datasets\n",
    "                    solver=\"adam\", \n",
    "                    #verbose=True,\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": y_test, \"Class\": mlp.predict(x_test)})\n",
    "y_pred.to_csv(\"data/reviews/reviews_pred_mlp4.csv\", index=False)\n",
    "print(\"model 4: logistic, adam, (1000, 1000)\")\n",
    "print(\"model 5\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (2000, 500, 50), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", # acc to sklearn logistic is best for big datasets\n",
    "                    solver=\"adam\", \n",
    "                    #verbose=True,\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": y_test, \"Class\": mlp.predict(x_test)})\n",
    "y_pred.to_csv(\"data/reviews/reviews_pred_mlp5.csv\", index=False)\n",
    "print(\"model 5: logistic, adam, (2000, 500, 50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f6bd4-43e3-4e13-9433-6a57decb5d55",
   "metadata": {},
   "source": [
    "### MLP: congress\n",
    "we go from 16 features to 2 labels\n",
    "\n",
    "rule of thumb suggests to use anything between 2 and 6 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6846fccf-6de7-464c-8a80-abf75a0ecde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding the labels to be 0 or 1\n",
    "# 0 is democrat\n",
    "# 1 is repulican\n",
    "y_congress_train.replace({\"democrat\": 0, \"republican\": 1}, inplace=True)\n",
    "# this way I can reuse my classification code from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69c08122-6cc2-4bb6-b17f-21a99f648516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     handicapped-infants  water-project-cost-sharing  \\\n",
       "0                    0.0                         1.0   \n",
       "1                    1.0                         0.0   \n",
       "2                    0.0                         0.0   \n",
       "3                    0.0                         1.0   \n",
       "4                    1.0                         0.0   \n",
       "..                   ...                         ...   \n",
       "213                  0.0                         1.0   \n",
       "214                  0.0                         1.0   \n",
       "215                  0.0                         0.0   \n",
       "216                  1.0                         1.0   \n",
       "217                  0.0                         1.0   \n",
       "\n",
       "     adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                  1.0                   0.0              0.0   \n",
       "1                                  0.0                   1.0              1.0   \n",
       "2                                  0.0                   1.0              1.0   \n",
       "3                                  1.0                   0.0              0.0   \n",
       "4                                  1.0                   1.0              1.0   \n",
       "..                                 ...                   ...              ...   \n",
       "213                                1.0                   0.0              0.0   \n",
       "214                                1.0                   0.0              1.0   \n",
       "215                                0.0                   1.0              1.0   \n",
       "216                                1.0                   0.0              1.0   \n",
       "217                                0.0                   1.0              1.0   \n",
       "\n",
       "     religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                            0.0                      1.0   \n",
       "1                            0.0                      1.0   \n",
       "2                            1.0                      0.0   \n",
       "3                            1.0                      1.0   \n",
       "4                            1.0                      1.0   \n",
       "..                           ...                      ...   \n",
       "213                          1.0                      0.0   \n",
       "214                          1.0                      0.0   \n",
       "215                          1.0                      0.0   \n",
       "216                          1.0                      0.0   \n",
       "217                          1.0                      0.0   \n",
       "\n",
       "     aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                          1.0         0.0          0.0   \n",
       "1                          0.0         0.0          1.0   \n",
       "2                          0.0         0.0          1.0   \n",
       "3                          1.0         1.0          0.0   \n",
       "4                          1.0         0.0          1.0   \n",
       "..                         ...         ...          ...   \n",
       "213                        1.0         1.0          1.0   \n",
       "214                        1.0         0.0          1.0   \n",
       "215                        0.0         0.0          0.0   \n",
       "216                        1.0         0.0          1.0   \n",
       "217                        0.0         0.0          1.0   \n",
       "\n",
       "     synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                            1.0                 0.0                     0.0   \n",
       "1                            0.0                 0.0                     0.0   \n",
       "2                            0.0                 1.0                     0.0   \n",
       "3                            1.0                 1.0                     0.0   \n",
       "4                            1.0                 1.0                     0.0   \n",
       "..                           ...                 ...                     ...   \n",
       "213                          0.0                 0.0                     1.0   \n",
       "214                          1.0                 0.0                     1.0   \n",
       "215                          0.0                 1.0                     1.0   \n",
       "216                          1.0                 0.0                     1.0   \n",
       "217                          0.0                 1.0                     1.0   \n",
       "\n",
       "     crime  duty-free-exports  export-administration-act-south-africa  \n",
       "0      0.0                1.0                                     1.0  \n",
       "1      1.0                1.0                                     1.0  \n",
       "2      1.0                0.0                                     1.0  \n",
       "3      0.0                1.0                                     1.0  \n",
       "4      1.0                1.0                                     1.0  \n",
       "..     ...                ...                                     ...  \n",
       "213    1.0                0.0                                     1.0  \n",
       "214    1.0                0.5                                     1.0  \n",
       "215    1.0                0.0                                     0.0  \n",
       "216    1.0                0.0                                     1.0  \n",
       "217    1.0                0.0                                     0.0  \n",
       "\n",
       "[218 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100    0\n",
       "215    1\n",
       "139    1\n",
       "178    0\n",
       "15     1\n",
       "      ..\n",
       "106    0\n",
       "14     0\n",
       "92     1\n",
       "179    0\n",
       "102    1\n",
       "Name: class, Length: 218, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     handicapped-infants  water-project-cost-sharing  \\\n",
       "0                    1.0                         0.0   \n",
       "1                    0.0                         0.0   \n",
       "2                    1.0                         1.0   \n",
       "3                    1.0                         1.0   \n",
       "4                    1.0                         0.0   \n",
       "..                   ...                         ...   \n",
       "212                  0.0                         0.0   \n",
       "213                  1.0                         0.0   \n",
       "214                  0.0                         0.0   \n",
       "215                  1.0                         0.0   \n",
       "216                  0.0                         1.0   \n",
       "\n",
       "     adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                  1.0                   0.0              1.0   \n",
       "1                                  0.0                   1.0              1.0   \n",
       "2                                  1.0                   0.0              0.0   \n",
       "3                                  1.0                   0.0              0.0   \n",
       "4                                  1.0                   0.0              1.0   \n",
       "..                                 ...                   ...              ...   \n",
       "212                                1.0                   0.0              0.0   \n",
       "213                                1.0                   0.0              0.0   \n",
       "214                                1.0                   1.0              1.0   \n",
       "215                                1.0                   0.0              0.0   \n",
       "216                                0.0                   1.0              1.0   \n",
       "\n",
       "     religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                            1.0                      1.0   \n",
       "1                            1.0                      0.0   \n",
       "2                            0.0                      1.0   \n",
       "3                            1.0                      1.0   \n",
       "4                            1.0                      0.0   \n",
       "..                           ...                      ...   \n",
       "212                          0.0                      1.0   \n",
       "213                          0.0                      1.0   \n",
       "214                          1.0                      1.0   \n",
       "215                          0.0                      1.0   \n",
       "216                          1.0                      0.0   \n",
       "\n",
       "     aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                          0.0         0.0          0.0   \n",
       "1                          0.0         0.0          1.0   \n",
       "2                          1.0         1.0          0.0   \n",
       "3                          1.0         1.0          1.0   \n",
       "4                          0.0         0.0          0.0   \n",
       "..                         ...         ...          ...   \n",
       "212                        1.0         1.0          1.0   \n",
       "213                        1.0         1.0          1.0   \n",
       "214                        1.0         0.0          1.0   \n",
       "215                        1.0         1.0          0.0   \n",
       "216                        0.0         0.0          0.0   \n",
       "\n",
       "     synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                            1.0                 0.0                     0.0   \n",
       "1                            0.0                 1.0                     1.0   \n",
       "2                            1.0                 0.0                     0.0   \n",
       "3                            0.0                 0.0                     0.0   \n",
       "4                            0.0                 0.0                     0.0   \n",
       "..                           ...                 ...                     ...   \n",
       "212                          1.0                 0.0                     0.0   \n",
       "213                          0.0                 0.0                     0.0   \n",
       "214                          0.0                 0.0                     0.0   \n",
       "215                          0.0                 0.0                     0.0   \n",
       "216                          0.0                 1.0                     1.0   \n",
       "\n",
       "     crime  duty-free-exports  export-administration-act-south-africa  \n",
       "0      1.0                0.0                                     1.0  \n",
       "1      1.0                0.0                                     1.0  \n",
       "2      0.0                1.0                                     1.0  \n",
       "3      0.0                1.0                                     1.0  \n",
       "4      0.0                0.0                                     1.0  \n",
       "..     ...                ...                                     ...  \n",
       "212    0.0                1.0                                     1.0  \n",
       "213    1.0                1.0                                     1.0  \n",
       "214    1.0                0.0                                     1.0  \n",
       "215    0.0                1.0                                     1.0  \n",
       "216    1.0                0.0                                     1.0  \n",
       "\n",
       "[217 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_congress_train)\n",
    "display(y_congress_train)\n",
    "display(x_congress_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9dd37f6-4593-421a-af7e-5c4155526770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495771670190274\n"
     ]
    }
   ],
   "source": [
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "learning_rate_init = 0.001 # default 0.001\n",
    "\n",
    "x_train = x_congress_train\n",
    "y_train = y_congress_train\n",
    "\n",
    "\n",
    "hidden_layers = (16) # best so far (16, 16, 2)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = hidden_layers, \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = activation_functions[1], \n",
    "                    solver=solvers[0], \n",
    "                    # verbose=True, # show progress\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "\n",
    "# cross validating\n",
    "# first param is the model incl its params, second is features, \n",
    "# third is class labels, cv is the k of k-fold-CV, scoring is the wanted scores\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "print(cross_val_score(mlp, x_train, y_train, cv=5, scoring=\"accuracy\").mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5098ecd7-5163-416f-92bf-267de3853fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "\n",
    "# testing params for congress\n",
    "congress_results = pd.DataFrame(columns=[\"classifier\", \"balanced_accuracy\", \n",
    "                                       \"time_taken\", \"activation_function\", \n",
    "                                       \"solver\", \"learning_rate\", \n",
    "                                       \"hidden_layer\"])\n",
    "# the scores we want\n",
    "# no point in checking for precision or recall\n",
    "# arguably, one may be worse than the other, but not for the sake of the research :D\n",
    "scoring = {'balanced_accuracy': 'balanced_accuracy'}\n",
    "\n",
    "# performing cross-fold validation on the training data to evaluate best parameters\n",
    "\n",
    "# filter out warnings (not sure if this is a good idea)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "x_train = x_congress_train\n",
    "y_train = y_congress_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_layers = [\n",
    "    (2),\n",
    "    (8),\n",
    "    (16),\n",
    "    (2, 2),\n",
    "    (8, 2),\n",
    "    (16, 8),\n",
    "    (16, 8, 2),\n",
    "    (16, 16, 8),\n",
    "    (16, 16, 2),\n",
    "    (16, 16, 16, 2),\n",
    "    (16, 16, 16, 16)\n",
    "]\n",
    "\n",
    "# cross-validation\n",
    "k = 10\n",
    "\n",
    "# running number to count iterations/permutations\n",
    "i = 0\n",
    "\n",
    "\n",
    "# only do the computation, if the following flag is true\n",
    "# it takes an hour or so to compute this, not necessary\n",
    "if True:\n",
    "    # iterate through all parameter permutations\n",
    "    # save accuracy, f1, precisiona and recall\n",
    "    for activation_function in activation_functions:\n",
    "        for solver in solvers:\n",
    "            for learning_rate in learning_rates:\n",
    "                for hidden_layer in hidden_layers:\n",
    "                    \n",
    "                    # make a model\n",
    "                    mlp = MLPClassifier(hidden_layer_sizes = hidden_layer, \n",
    "                                        max_iter=300, # epochs\n",
    "                                        activation = activation_function, \n",
    "                                        solver=solver, \n",
    "                                        learning_rate = learning_rate,\n",
    "                                        learning_rate_init = learning_rate_init,\n",
    "                                        random_state=1234 # kind of seed\n",
    "                                       )\n",
    "\n",
    "                    # cross_validate() returns a dictionary with results\n",
    "                    # cv = k for f-fold cross-validation\n",
    "                    cv_results = cross_validate(mlp, x_train, y_train, cv=k, scoring=scoring, return_train_score=True)\n",
    "                    \n",
    "                    # extract the result values and take the mean of the k iterations\n",
    "                    fit_time = cv_results[\"fit_time\"].mean()\n",
    "                    balanced_accuracy = cv_results[\"test_balanced_accuracy\"].mean()\n",
    "                    \n",
    "                    # print out the running number, the accuracy and the parameters\n",
    "                    print(i, \"- acc:\", balanced_accuracy, \"-, time:\",  fit_time, end=\"\\r\")\n",
    "                    \n",
    "                    # save everything\n",
    "                    congress_results = pd.concat([congress_results, pd.DataFrame({\n",
    "                        \"classifier\": \"mlp\",\n",
    "                        \"balanced_accuracy\": [balanced_accuracy],\n",
    "                        \"time_taken\": fit_time,\n",
    "                        \"activation_function\": activation_function,\n",
    "                        \"solver\": solver,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"hidden_layer\": str(hidden_layer)                        \n",
    "                    })], ignore_index=True)\n",
    "                    i += 1;\n",
    " \n",
    "    display(congress_results)\n",
    "    \n",
    "    # saving the results as a pickle\n",
    "    with open('data/congress/congress_results_k10.pickle', 'wb') as f:\n",
    "        pickle.dump(congress_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28cf849a-210e-4274-b4d2-330ffe4b01ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hidden_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.047264</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.084928</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.044197</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(16, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(16, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(16, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.961134</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(16, 8, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.961134</td>\n",
       "      <td>0.233120</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(16, 8, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.961134</td>\n",
       "      <td>0.208312</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(16, 8, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.960165</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.960165</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.960165</td>\n",
       "      <td>0.049969</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(16, 16, 16, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959272</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959272</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959272</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959150</td>\n",
       "      <td>0.216131</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>(16, 16, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959150</td>\n",
       "      <td>0.205934</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>(16, 16, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.959150</td>\n",
       "      <td>0.224672</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>constant</td>\n",
       "      <td>(16, 16, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.955701</td>\n",
       "      <td>0.030122</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.955701</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.955701</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier  balanced_accuracy  time_taken activation_function solver  \\\n",
       "10         mlp           0.975893    0.047264            logistic  lbfgs   \n",
       "32         mlp           0.975893    0.084928            logistic  lbfgs   \n",
       "21         mlp           0.975893    0.044197            logistic  lbfgs   \n",
       "16         mlp           0.973214    0.014908            logistic  lbfgs   \n",
       "5          mlp           0.973214    0.014848            logistic  lbfgs   \n",
       "27         mlp           0.973214    0.014618            logistic  lbfgs   \n",
       "24         mlp           0.969643    0.008914            logistic  lbfgs   \n",
       "2          mlp           0.969643    0.009134            logistic  lbfgs   \n",
       "13         mlp           0.969643    0.009614            logistic  lbfgs   \n",
       "112        mlp           0.962225    0.014998                tanh  lbfgs   \n",
       "101        mlp           0.962225    0.013293                tanh  lbfgs   \n",
       "123        mlp           0.962225    0.016805                tanh  lbfgs   \n",
       "292        mlp           0.961134    0.334190                relu   adam   \n",
       "270        mlp           0.961134    0.233120                relu   adam   \n",
       "281        mlp           0.961134    0.208312                relu   adam   \n",
       "219        mlp           0.960165    0.031877                relu  lbfgs   \n",
       "208        mlp           0.960165    0.031319                relu  lbfgs   \n",
       "230        mlp           0.960165    0.049969                relu  lbfgs   \n",
       "198        mlp           0.959272    0.011989                relu  lbfgs   \n",
       "220        mlp           0.959272    0.011509                relu  lbfgs   \n",
       "209        mlp           0.959272    0.011919                relu  lbfgs   \n",
       "184        mlp           0.959150    0.216131                tanh   adam   \n",
       "195        mlp           0.959150    0.205934                tanh   adam   \n",
       "173        mlp           0.959150    0.224672                tanh   adam   \n",
       "221        mlp           0.957563    0.013147                relu  lbfgs   \n",
       "210        mlp           0.957563    0.011757                relu  lbfgs   \n",
       "199        mlp           0.957563    0.011605                relu  lbfgs   \n",
       "99         mlp           0.955701    0.030122                tanh  lbfgs   \n",
       "110        mlp           0.955701    0.021125                tanh  lbfgs   \n",
       "121        mlp           0.955701    0.023767                tanh  lbfgs   \n",
       "\n",
       "    learning_rate      hidden_layer  \n",
       "10       constant  (16, 16, 16, 16)  \n",
       "32       adaptive  (16, 16, 16, 16)  \n",
       "21     invscaling  (16, 16, 16, 16)  \n",
       "16     invscaling           (16, 8)  \n",
       "5        constant           (16, 8)  \n",
       "27       adaptive           (16, 8)  \n",
       "24       adaptive                16  \n",
       "2        constant                16  \n",
       "13     invscaling                16  \n",
       "112    invscaling                16  \n",
       "101      constant                16  \n",
       "123      adaptive                16  \n",
       "292      adaptive        (16, 8, 2)  \n",
       "270      constant        (16, 8, 2)  \n",
       "281    invscaling        (16, 8, 2)  \n",
       "219    invscaling  (16, 16, 16, 16)  \n",
       "208      constant  (16, 16, 16, 16)  \n",
       "230      adaptive  (16, 16, 16, 16)  \n",
       "198      constant                 2  \n",
       "220      adaptive                 2  \n",
       "209    invscaling                 2  \n",
       "184    invscaling       (16, 16, 2)  \n",
       "195      adaptive       (16, 16, 2)  \n",
       "173      constant       (16, 16, 2)  \n",
       "221      adaptive                 8  \n",
       "210    invscaling                 8  \n",
       "199      constant                 8  \n",
       "99       constant                 2  \n",
       "110    invscaling                 2  \n",
       "121      adaptive                 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the saved results\n",
    "with open('data/congress/congress_results_k10.pickle', 'rb') as handle:\n",
    "    congress_results = pickle.load(handle)\n",
    "\n",
    "display(congress_results.sort_values(\"balanced_accuracy\", ascending=False).head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204593a0-b505-4286-9242-a6fc5865bdc7",
   "metadata": {},
   "source": [
    "#### best params & testing\n",
    "learning_rate apparently makes no difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf02849e-f328-4ebf-9f05-1578ab990bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_congress_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m x_train \u001B[38;5;241m=\u001B[39m \u001B[43mx_congress_train\u001B[49m\n\u001B[1;32m      2\u001B[0m y_train \u001B[38;5;241m=\u001B[39m y_congress_train\n\u001B[1;32m      5\u001B[0m x_test \u001B[38;5;241m=\u001B[39m x_congress_test\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_congress_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = x_congress_train\n",
    "y_train = y_congress_train\n",
    "\n",
    "\n",
    "x_test = x_congress_test\n",
    "y_test = y_fert_test\n",
    "\n",
    "print(\"best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (16, 16, 16, 16), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": x_test, \"class\": mlp.predict(x_test)})\n",
    "y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "y_pred.to_csv(\"data/congress/congress_pred_mlp1.csv\", index=False)\n",
    "print(\"model 1: logistic, lbfgs, (16, 16, 16, 16)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"2nd best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (16, 8), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": x_test, \"class\": mlp.predict(x_test)})\n",
    "y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "y_pred.to_csv(\"data/congress/congress_pred_mlp2.csv\", index=False)\n",
    "print(\"model 2: logistic, lbfgs, (16, 8)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"3rd best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (16), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": x_congress_test_ID, \"class\": mlp.predict(x_test)})\n",
    "y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "y_pred.to_csv(\"data/congress/congress_pred_mlp3.csv\", index=False)\n",
    "print(\"model 3: logistic, lbfgs, (16)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"4th best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (16), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"tanh\", \n",
    "                    solver=\"lbfgs\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": x_congress_test_ID, \"class\": mlp.predict(x_test)})\n",
    "y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "y_pred.to_csv(\"data/congress/congress_pred_mlp4.csv\", index=False)\n",
    "print(\"model 4: tanh, lbfgs, (16)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"5th best accuracy\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (16, 8, 2), \n",
    "                    max_iter=300, # epochs\n",
    "                    activation = \"relu\", \n",
    "                    solver=\"adam\", \n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred = pd.DataFrame({\"ID\": x_test, \"class\": mlp.predict(x_test)})\n",
    "y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "y_pred.to_csv(\"data/congress/congress_pred_mlp5.csv\", index=False)\n",
    "print(\"model 5: relu, adam, (16, 8, 2)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfaad00c-1c11-4480-ae45-d663f346ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handicapped-infants</th>\n",
       "      <th>water-project-cost-sharing</th>\n",
       "      <th>adoption-of-the-budget-resolution</th>\n",
       "      <th>physician-fee-freeze</th>\n",
       "      <th>el-salvador-aid</th>\n",
       "      <th>religious-groups-in-schools</th>\n",
       "      <th>anti-satellite-test-ban</th>\n",
       "      <th>aid-to-nicaraguan-contras</th>\n",
       "      <th>mx-missile</th>\n",
       "      <th>immigration</th>\n",
       "      <th>synfuels-crporation-cutback</th>\n",
       "      <th>education-spending</th>\n",
       "      <th>superfund-right-to-sue</th>\n",
       "      <th>crime</th>\n",
       "      <th>duty-free-exports</th>\n",
       "      <th>export-administration-act-south-africa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     handicapped-infants  water-project-cost-sharing  \\\n",
       "0                    1.0                         0.0   \n",
       "1                    0.0                         0.0   \n",
       "2                    1.0                         1.0   \n",
       "3                    1.0                         1.0   \n",
       "4                    1.0                         0.0   \n",
       "..                   ...                         ...   \n",
       "212                  NaN                         0.0   \n",
       "213                  1.0                         0.0   \n",
       "214                  0.0                         0.0   \n",
       "215                  1.0                         0.0   \n",
       "216                  0.0                         NaN   \n",
       "\n",
       "     adoption-of-the-budget-resolution  physician-fee-freeze  el-salvador-aid  \\\n",
       "0                                  1.0                   0.0              1.0   \n",
       "1                                  0.0                   1.0              1.0   \n",
       "2                                  1.0                   0.0              0.0   \n",
       "3                                  1.0                   0.0              0.0   \n",
       "4                                  1.0                   0.0              1.0   \n",
       "..                                 ...                   ...              ...   \n",
       "212                                1.0                   0.0              0.0   \n",
       "213                                1.0                   0.0              0.0   \n",
       "214                                1.0                   1.0              1.0   \n",
       "215                                1.0                   0.0              0.0   \n",
       "216                                0.0                   1.0              1.0   \n",
       "\n",
       "     religious-groups-in-schools  anti-satellite-test-ban  \\\n",
       "0                            1.0                      1.0   \n",
       "1                            1.0                      0.0   \n",
       "2                            0.0                      1.0   \n",
       "3                            1.0                      1.0   \n",
       "4                            1.0                      0.0   \n",
       "..                           ...                      ...   \n",
       "212                          0.0                      1.0   \n",
       "213                          0.0                      1.0   \n",
       "214                          1.0                      1.0   \n",
       "215                          0.0                      1.0   \n",
       "216                          1.0                      0.0   \n",
       "\n",
       "     aid-to-nicaraguan-contras  mx-missile  immigration  \\\n",
       "0                          0.0         0.0          0.0   \n",
       "1                          0.0         0.0          1.0   \n",
       "2                          1.0         1.0          0.0   \n",
       "3                          1.0         1.0          1.0   \n",
       "4                          0.0         0.0          0.0   \n",
       "..                         ...         ...          ...   \n",
       "212                        1.0         1.0          1.0   \n",
       "213                        1.0         1.0          1.0   \n",
       "214                        1.0         0.0          1.0   \n",
       "215                        1.0         1.0          0.0   \n",
       "216                        0.0         0.0          0.0   \n",
       "\n",
       "     synfuels-crporation-cutback  education-spending  superfund-right-to-sue  \\\n",
       "0                            1.0                 0.0                     0.0   \n",
       "1                            0.0                 1.0                     1.0   \n",
       "2                            1.0                 0.0                     0.0   \n",
       "3                            0.0                 0.0                     NaN   \n",
       "4                            0.0                 0.0                     0.0   \n",
       "..                           ...                 ...                     ...   \n",
       "212                          1.0                 NaN                     0.0   \n",
       "213                          0.0                 0.0                     0.0   \n",
       "214                          0.0                 0.0                     0.0   \n",
       "215                          0.0                 0.0                     0.0   \n",
       "216                          0.0                 1.0                     1.0   \n",
       "\n",
       "     crime  duty-free-exports  export-administration-act-south-africa  \n",
       "0      1.0                0.0                                     1.0  \n",
       "1      1.0                0.0                                     1.0  \n",
       "2      0.0                1.0                                     1.0  \n",
       "3      0.0                1.0                                     NaN  \n",
       "4      0.0                0.0                                     1.0  \n",
       "..     ...                ...                                     ...  \n",
       "212    0.0                1.0                                     NaN  \n",
       "213    1.0                1.0                                     1.0  \n",
       "214    1.0                0.0                                     1.0  \n",
       "215    0.0                1.0                                     NaN  \n",
       "216    1.0                0.0                                     1.0  \n",
       "\n",
       "[217 rows x 16 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_congress_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de58ac7f-b399-45cc-b7fb-8050f90863c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000594898348559961"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_congress_train\n",
    "y_train = y_congress_train\n",
    "\n",
    "\n",
    "x_test = x_congress_test\n",
    "y_test = y_fert_test\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (8), \n",
    "                    max_iter=500, # epochs\n",
    "                    activation = \"logistic\", \n",
    "                    solver=\"lbfgs\", \n",
    "                  #  verbose=True,\n",
    "                    random_state=1234 # kind of seed\n",
    "                   )\n",
    "mlp.fit(x_train, y_train)\n",
    "#y_pred = pd.DataFrame({\"ID\": x_congress_test_ID, \"class\": mlp.predict(x_test)})\n",
    "#y_pred[\"class\"] = y_pred[\"class\"].apply(lambda x: \"republican\" if x else \"democrat\")\n",
    "#y_pred.to_csv(\"data/congress/congress_pred_mlp5.csv\", index=False)\n",
    "mlp.loss_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
